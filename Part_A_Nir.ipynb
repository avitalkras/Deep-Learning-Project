{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.353186Z",
     "iopub.status.busy": "2026-01-02T12:52:12.352537Z",
     "iopub.status.idle": "2026-01-02T12:52:12.357376Z",
     "shell.execute_reply": "2026-01-02T12:52:12.356526Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.353146Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.359071Z",
     "iopub.status.busy": "2026-01-02T12:52:12.358777Z",
     "iopub.status.idle": "2026-01-02T12:52:12.379663Z",
     "shell.execute_reply": "2026-01-02T12:52:12.378989Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.359036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def is_van_gogh(artist_name: str) -> int:\n",
    "    return int(\"van-gogh\" in artist_name.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.381016Z",
     "iopub.status.busy": "2026-01-02T12:52:12.380663Z",
     "iopub.status.idle": "2026-01-02T12:52:12.568222Z",
     "shell.execute_reply": "2026-01-02T12:52:12.567238Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.380994Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# שים לב לשם הפרמטר key\n",
    "wandb.login(key=\"16d1bc863b28f81253ac0ee253b453393791a7e1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # ****Data**** ****Preparation**** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.570699Z",
     "iopub.status.busy": "2026-01-02T12:52:12.570379Z",
     "iopub.status.idle": "2026-01-02T12:52:12.606144Z",
     "shell.execute_reply": "2026-01-02T12:52:12.605146Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.570666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"/kaggle/input/wikiart/Post_Impressionism\"\n",
    "\n",
    "records = []\n",
    "\n",
    "for fname in os.listdir(base_dir):\n",
    "    if not fname.lower().endswith((\".jpg\", \".png\")):\n",
    "        continue\n",
    "\n",
    "    artist = fname.split(\"_\")[0] #takes the first item of the split- the name of artist\n",
    "\n",
    "    records.append({\n",
    "        \"filepath\": os.path.join(base_dir, fname),\n",
    "        \"artist\": artist,\n",
    "        \"is_van_gogh\": int(\"van-gogh\" in artist.lower())\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **check** **the** **dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.608320Z",
     "iopub.status.busy": "2026-01-02T12:52:12.608017Z",
     "iopub.status.idle": "2026-01-02T12:52:12.617571Z",
     "shell.execute_reply": "2026-01-02T12:52:12.616779Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.608291Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>artist</th>\n",
       "      <th>is_van_gogh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/wikiart/Post_Impressionism/paul-...</td>\n",
       "      <td>paul-cezanne</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/wikiart/Post_Impressionism/suzan...</td>\n",
       "      <td>suzanne-valadon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/wikiart/Post_Impressionism/alber...</td>\n",
       "      <td>albert-marquet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/wikiart/Post_Impressionism/vince...</td>\n",
       "      <td>vincent-van-gogh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/wikiart/Post_Impressionism/paul-...</td>\n",
       "      <td>paul-gauguin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath            artist  \\\n",
       "0  /kaggle/input/wikiart/Post_Impressionism/paul-...      paul-cezanne   \n",
       "1  /kaggle/input/wikiart/Post_Impressionism/suzan...   suzanne-valadon   \n",
       "2  /kaggle/input/wikiart/Post_Impressionism/alber...    albert-marquet   \n",
       "3  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n",
       "4  /kaggle/input/wikiart/Post_Impressionism/paul-...      paul-gauguin   \n",
       "\n",
       "   is_van_gogh  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            1  \n",
       "4            0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.619199Z",
     "iopub.status.busy": "2026-01-02T12:52:12.618807Z",
     "iopub.status.idle": "2026-01-02T12:52:12.637913Z",
     "shell.execute_reply": "2026-01-02T12:52:12.637119Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.619165Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_van_gogh\n",
      "0    5445\n",
      "1    1005\n",
      "Name: count, dtype: int64\n",
      "                                             filepath            artist  \\\n",
      "3   /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n",
      "9   /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n",
      "16  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n",
      "17  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n",
      "18  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n",
      "\n",
      "    is_van_gogh  \n",
      "3             1  \n",
      "9             1  \n",
      "16            1  \n",
      "17            1  \n",
      "18            1  \n"
     ]
    }
   ],
   "source": [
    "print (df[\"is_van_gogh\"].value_counts())\n",
    "print (df[df[\"is_van_gogh\"] == 1].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *splitting the dataframe, and check it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.639868Z",
     "iopub.status.busy": "2026-01-02T12:52:12.638607Z",
     "iopub.status.idle": "2026-01-02T12:52:12.660722Z",
     "shell.execute_reply": "2026-01-02T12:52:12.660095Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.639832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Initial split - 70% for training and 30% for a temporary set (temp_df)\n",
    "train_df, temp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.3,           # Reserves 30% of the data for validation and testing\n",
    "    stratify=df[\"is_van_gogh\"], # Ensures class proportions are preserved across splits\n",
    "    random_state=42          # Sets a seed for reproducibility\n",
    ")\n",
    "\n",
    "# Step 2: Second split - Divide the 30% temporary set equally into validation and test sets\n",
    "# This results in 15% of the total data for validation and 15% for testing\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.5,           # Splits the 30% into two equal 15% parts\n",
    "    stratify=temp_df[\"is_van_gogh\"], # Maintains class balance in the remaining subsets\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.662292Z",
     "iopub.status.busy": "2026-01-02T12:52:12.661751Z",
     "iopub.status.idle": "2026-01-02T12:52:12.671032Z",
     "shell.execute_reply": "2026-01-02T12:52:12.670366Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.662268Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 4515 rows (70.0%)\n",
      "Val set:   967 rows (15.0%)\n",
      "Test set:  968 rows (15.0%)\n",
      "------------------------------\n",
      "Class distribution per split:\n",
      "\n",
      "Train:\n",
      " is_van_gogh\n",
      "0    0.844075\n",
      "1    0.155925\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Val:\n",
      " is_van_gogh\n",
      "0    0.844881\n",
      "1    0.155119\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Test:\n",
      " is_van_gogh\n",
      "0    0.844008\n",
      "1    0.155992\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of rows\n",
    "total_count = len(df)\n",
    "\n",
    "# Print percentages of each split relative to the original dataset\n",
    "print(f\"Train set: {len(train_df)} rows ({len(train_df) / total_count:.1%})\")\n",
    "print(f\"Val set:   {len(val_df)} rows ({len(val_df) / total_count:.1%})\")\n",
    "print(f\"Test set:  {len(test_df)} rows ({len(test_df) / total_count:.1%})\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Print class distribution (counts) to verify stratification\n",
    "print(\"Class distribution per split:\")\n",
    "print(\"\\nTrain:\\n\", train_df[\"is_van_gogh\"].value_counts(normalize=True)) # normalize=True gives ratios\n",
    "print(\"\\nVal:\\n\",   val_df[\"is_van_gogh\"].value_counts(normalize=True))\n",
    "print(\"\\nTest:\\n\",  test_df[\"is_van_gogh\"].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trasfomation class for VGG & AlexNet standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.672460Z",
     "iopub.status.busy": "2026-01-02T12:52:12.671997Z",
     "iopub.status.idle": "2026-01-02T12:52:12.686444Z",
     "shell.execute_reply": "2026-01-02T12:52:12.685863Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.672439Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\"\"\"\n",
    "1 Standard transformations for models pre-trained on ImageNet ( VGG, AlexNet)\n",
    "2 Resizes the image to 224x224, the standard input size for VGG and AlexNet\n",
    "3 Converts the image to a PyTorch tensor and scales pixels to the [0, 1] range\n",
    "4 Normalizes the tensor using ImageNet's mean and standard deviation.\n",
    "5 Essential for maintaining consistency with VGG and AlexNet pre-trained weights.\n",
    "\n",
    "\n",
    "augmentaion used: \n",
    "- RandomResizedCrop: Crops a random portion of the image and resizes it to 224x224. \n",
    "  This helps the model become invariant to scale and object position.\n",
    "- RandomHorizontalFlip: Flips the image horizontally with a 50% probability. \n",
    "  Useful for art since composition can be mirrored without losing stylistic meaning.\n",
    "- RandomRotation: Rotates the image by up to 10 degrees to handle slight tilts.\n",
    "- ColorJitter: Randomly changes brightness, contrast, saturation, and hue. \n",
    "  This is crucial for Van Gogh's work as it makes the model robust to different lighting \n",
    "  conditions and minor color shifts in art photography.\n",
    "- ToTensor & Normalize: Standard ImageNet preprocessing for model compatibility.\n",
    "\"\"\"\n",
    "# will be used to trasform the images to normalized tensor object  --> base_transform(un-normalized picture) and the Augmentaions\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2,\n",
    "        contrast=0.2,\n",
    "        saturation=0.2,\n",
    "        hue=0.05\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.688847Z",
     "iopub.status.busy": "2026-01-02T12:52:12.688545Z",
     "iopub.status.idle": "2026-01-02T12:52:12.705038Z",
     "shell.execute_reply": "2026-01-02T12:52:12.704369Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.688825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Like the Train transforom but without the augmentaions\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.706557Z",
     "iopub.status.busy": "2026-01-02T12:52:12.705945Z",
     "iopub.status.idle": "2026-01-02T12:52:12.720382Z",
     "shell.execute_reply": "2026-01-02T12:52:12.719739Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.706534Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class VanGoghDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)   \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        image = Image.open(row[\"filepath\"]).convert(\"RGB\")\n",
    "        label = row[\"is_van_gogh\"]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.721884Z",
     "iopub.status.busy": "2026-01-02T12:52:12.721303Z",
     "iopub.status.idle": "2026-01-02T12:52:12.737691Z",
     "shell.execute_reply": "2026-01-02T12:52:12.737048Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.721862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = VanGoghDataset(train_df, transform=train_transform)\n",
    "val_dataset   = VanGoghDataset(val_df,   transform=eval_transform)\n",
    "test_dataset  = VanGoghDataset(test_df,  transform=eval_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.738826Z",
     "iopub.status.busy": "2026-01-02T12:52:12.738538Z",
     "iopub.status.idle": "2026-01-02T12:52:12.805375Z",
     "shell.execute_reply": "2026-01-02T12:52:12.804648Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.738785Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1179, -2.1179, -2.1179,  ...,  0.7933,  0.7933, -2.1179],\n",
       "         [ 0.4166,  0.5022,  0.6734,  ...,  0.7933,  0.8104, -2.1179],\n",
       "         [ 0.5707,  0.6734,  0.7591,  ...,  0.7933,  0.8104, -2.1179],\n",
       "         ...,\n",
       "         [-2.1179, -0.8849, -1.1075,  ..., -0.6281, -0.4739, -0.3883],\n",
       "         [-2.1179, -0.7308, -1.0219,  ..., -0.6794, -0.6109, -0.6109],\n",
       "         [-2.1179, -0.9705, -1.0219,  ..., -2.1179, -2.1179, -2.1179]],\n",
       "\n",
       "        [[-2.0357, -2.0357, -2.0357,  ...,  0.8529,  0.8354, -2.0357],\n",
       "         [ 0.2927,  0.2227,  0.4328,  ...,  0.8880,  0.8704, -2.0357],\n",
       "         [ 0.3803,  0.4328,  0.6078,  ...,  0.9930,  0.9405, -2.0357],\n",
       "         ...,\n",
       "         [-2.0357, -0.8627, -1.0378,  ..., -0.4776, -0.2150, -0.1275],\n",
       "         [-2.0357, -0.7402, -1.0028,  ..., -0.3901, -0.2850, -0.3375],\n",
       "         [-2.0357, -1.0203, -1.0378,  ..., -2.0357, -2.0357, -2.0357]],\n",
       "\n",
       "        [[-1.8044, -1.8044, -1.8044,  ...,  0.3916,  0.3742, -1.8044],\n",
       "         [-0.2881, -0.3578, -0.0092,  ...,  0.4962,  0.4439, -1.8044],\n",
       "         [-0.2358, -0.1487,  0.1128,  ...,  0.5659,  0.5136, -1.8044],\n",
       "         ...,\n",
       "         [-1.8044, -0.7238, -0.8458,  ..., -1.2816, -1.0898, -1.0724],\n",
       "         [-1.8044, -0.5495, -0.7761,  ..., -1.2293, -1.0550, -1.1247],\n",
       "         [-1.8044, -0.9156, -0.8981,  ..., -1.8044, -1.8044, -1.8044]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.806549Z",
     "iopub.status.busy": "2026-01-02T12:52:12.806301Z",
     "iopub.status.idle": "2026-01-02T12:52:12.863143Z",
     "shell.execute_reply": "2026-01-02T12:52:12.862420Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.806517Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# sanity check\n",
    "# Retrieve images only (index 0 of the returned tuple)\n",
    "img1 = test_dataset[0][0]\n",
    "img2 = test_dataset.__getitem__(0)[0]\n",
    "print(torch.equal(img1, img2)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making  DataLoader obj to later use in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.864280Z",
     "iopub.status.busy": "2026-01-02T12:52:12.864050Z",
     "iopub.status.idle": "2026-01-02T12:52:12.868626Z",
     "shell.execute_reply": "2026-01-02T12:52:12.867996Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.864258Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader for the training set\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,      # Number of images per training step\n",
    "    shuffle=True,       # Shuffle the data to prevent the model from learning the order\n",
    "    num_workers=2       # Use 2 parallel CPU processes to load data faster\n",
    ")\n",
    "\n",
    "# DataLoader for the validation set\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,      # Typically matches the training batch size\n",
    "    shuffle=False,      # No need to shuffle during evaluation\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.869859Z",
     "iopub.status.busy": "2026-01-02T12:52:12.869543Z",
     "iopub.status.idle": "2026-01-02T12:52:12.882202Z",
     "shell.execute_reply": "2026-01-02T12:52:12.881636Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.869837Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# הגדרת המכשיר - אם יש GPU ב-Kaggle, הוא ישתמש בו\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Working on: {device}\") # ב-Kaggle זה צריך להדפיס cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:12.883208Z",
     "iopub.status.busy": "2026-01-02T12:52:12.882974Z",
     "iopub.status.idle": "2026-01-02T12:52:14.488004Z",
     "shell.execute_reply": "2026-01-02T12:52:14.487391Z",
     "shell.execute_reply.started": "2026-01-02T12:52:12.883189Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "model = models.vgg19(pretrained=True)\n",
    "\n",
    "model.classifier[-1] = nn.Linear(\n",
    "    model.classifier[-1].in_features, 2\n",
    ")\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:14.489131Z",
     "iopub.status.busy": "2026-01-02T12:52:14.488863Z",
     "iopub.status.idle": "2026-01-02T12:52:14.493081Z",
     "shell.execute_reply": "2026-01-02T12:52:14.492349Z",
     "shell.execute_reply.started": "2026-01-02T12:52:14.489103Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=4096, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Print only the last layer of the classifier\n",
    "print(model.classifier[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:14.494691Z",
     "iopub.status.busy": "2026-01-02T12:52:14.494040Z",
     "iopub.status.idle": "2026-01-02T12:52:14.510876Z",
     "shell.execute_reply": "2026-01-02T12:52:14.510151Z",
     "shell.execute_reply.started": "2026-01-02T12:52:14.494655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:14.512169Z",
     "iopub.status.busy": "2026-01-02T12:52:14.511860Z",
     "iopub.status.idle": "2026-01-02T12:52:14.525976Z",
     "shell.execute_reply": "2026-01-02T12:52:14.525240Z",
     "shell.execute_reply.started": "2026-01-02T12:52:14.512138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()    # each grad will start with grad = zero\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # בדיקה אם יש ריצה פעילה ב-W&B כדי למנוע את השגיאה שקיבלת\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\"batch_loss\": loss.item()})\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\"val_batch_loss\": loss.item()})\n",
    "            \n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T12:52:14.527176Z",
     "iopub.status.busy": "2026-01-02T12:52:14.526907Z",
     "iopub.status.idle": "2026-01-02T12:58:32.215366Z",
     "shell.execute_reply": "2026-01-02T12:58:32.214506Z",
     "shell.execute_reply.started": "2026-01-02T12:52:14.527144Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260102_125214-3fms02io</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io' target=\"_blank\">Initial_Test</a></strong> to <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▆█▃▄▄▂▅▅▃▄▄▃▃▅▅▂▄▃▁▁▄▅▄▃▂▄▃▂▃▂▃▆▂▁▂▃▂▂▂▅</td></tr><tr><td>val_batch_loss</td><td>▅▆▅▇▅▇▆▃▆█▆▇█▄▅▆▆▂▅█▁▁▃▃▂▅▂▁▆▃▄▂▃▃▆▄▂▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.04852</td></tr><tr><td>val_batch_loss</td><td>0.08983</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Initial_Test</strong> at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io</a><br> View project at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260102_125214-3fms02io/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"VanGogh_Classifier\", \n",
    "    name=\"Initial_Test\",\n",
    "    config={\n",
    "        \"architecture\": \"VGG19\",\n",
    "        \"epochs\": 3\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = eval_one_epoch(model, val_loader, criterion)\n",
    "    # ...\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T13:02:29.198303Z",
     "iopub.status.busy": "2026-01-02T13:02:29.197534Z",
     "iopub.status.idle": "2026-01-02T13:02:29.205709Z",
     "shell.execute_reply": "2026-01-02T13:02:29.204962Z",
     "shell.execute_reply.started": "2026-01-02T13:02:29.198275Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def objective(trial):\n",
    "    # 1. בחירת היפר-פרמטרים על ידי Optuna\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    \n",
    "    # הגדרת ה-DataLoaders בתוך הפונקציה כדי להשתמש ב-batch_size שנבחר\n",
    "    curr_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2) # shuffe is important between each epoch\n",
    "    curr_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    # 2. אתחול ריצה ב-Weights & Biases (חובה לפי ההנחיות)\n",
    "    run = wandb.init(\n",
    "        project=\"VanGogh_Classifier\",\n",
    "        name=f\"trial_{trial.number}\",\n",
    "        config={\n",
    "            \"lr\": lr, \n",
    "            \"optimizer\": optimizer_name, \n",
    "            \"batch_size\": batch_size,\n",
    "            \"model\": \"VGG19\"\n",
    "        },\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    # 3. בניית המודל - בכל פעם מחדש עבור הניסיון הנוכחי\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 2)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 4. לולאת אימון לפי מספר Epochs מוגדר\n",
    "    num_epochs = 5 \n",
    "    for epoch in range(num_epochs):\n",
    "        # אימון והערכה בעזרת הפונקציות שכתבת\n",
    "        train_loss = train_one_epoch(model, curr_train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc = eval_one_epoch(model, curr_val_loader, criterion)\n",
    "        \n",
    "        # דיווח מדדים ל-W&B בסוף כל Epoch\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch, \n",
    "            \"train_loss\": train_loss, \n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_acc\": val_acc\n",
    "        })\n",
    "        \n",
    "        # דיווח ל-Optuna ובדיקת \"גיזום\" (Pruning) לחיסכון בזמן\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            run.finish()\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # סגירת הריצה ב-W&B והחזרת התוצאה ל-Optuna\n",
    "    run.finish()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T13:02:35.526262Z",
     "iopub.status.busy": "2026-01-02T13:02:35.525616Z",
     "iopub.status.idle": "2026-01-02T13:12:01.666945Z",
     "shell.execute_reply": "2026-01-02T13:12:01.666240Z",
     "shell.execute_reply.started": "2026-01-02T13:02:35.526236Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-02 13:02:35,527]\u001b[0m A new study created in memory with name: no-name-b63628b2-ab88-4585-83ca-7418a14a4700\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20260102_130235-8jpgwyyo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▅▄▁▂▂▄▂▆▄▃▂▁▅▃▄▃▂▂▃▃▄▃▂▃▂▂▁█▄▆▂▂▁▁▂▃▁▁▂▃</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_acc</td><td>▁█▇██</td></tr><tr><td>val_batch_loss</td><td>▅▇▆▇▅▅▇█▂▅▃▃▃▅▂▂▁▁▄▂▁█▁▂▁▃▁▄▄▁▁▂▁▅▂▃▃▃▂▂</td></tr><tr><td>val_loss</td><td>█▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.0237</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.14442</td></tr><tr><td>val_acc</td><td>0.94002</td></tr><tr><td>val_batch_loss</td><td>0.03188</td></tr><tr><td>val_loss</td><td>0.14641</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo</a><br> View project at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20260102_130235-8jpgwyyo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2026-01-02 13:12:01,662]\u001b[0m Trial 0 finished with value: 0.9400206825232679 and parameters: {'lr': 0.0012011055202177864, 'optimizer': 'SGD', 'batch_size': 16}. Best is trial 0 with value: 0.9400206825232679.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- הבדיקה הסתיימה בהצלחה! ---\n",
      "הפרמטרים הטובים ביותר שמצאנו ב-5 דקות: {'lr': 0.0012011055202177864, 'optimizer': 'SGD', 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "# יצירת המחקר\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# הרצה לבדיקה ראשונית - 5 דקות בלבד (300 שניות)\n",
    "study.optimize(objective, timeout=300) \n",
    "\n",
    "print(\"--- הבדיקה הסתיימה בהצלחה! ---\")\n",
    "print(\"הפרמטרים הטובים ביותר שמצאנו ב-5 דקות:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2026-01-02T12:58:32.226691Z",
     "iopub.status.idle": "2026-01-02T12:58:32.227249Z",
     "shell.execute_reply": "2026-01-02T12:58:32.227095Z",
     "shell.execute_reply.started": "2026-01-02T12:58:32.227067Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "############# FOR LATER USE ###################\n",
    "\n",
    "def imshow(tensor):\n",
    "    \"\"\"\n",
    "    Converts a normalized PyTorch tensor back to a visual image and displays it.\n",
    "    \n",
    "    The function reverses the ImageNet normalization by multiplying by the \n",
    "    standard deviation and adding the mean. It also clips values to the \n",
    "    [0, 1] range to ensure compatibility with matplotlib.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.Tensor): A normalized image tensor of shape (C, H, W).\n",
    "    \"\"\"\n",
    "    img = tensor.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    \n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2477766,
     "sourceId": 4202543,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Part A - Van Gogh Painting Classifier\n\n## Deep Learning Project - Tel Aviv University\n\nThis notebook implements a binary classifier to identify Van Gogh paintings using transfer learning with VGG19.\n\n### Overview:\n1. **Load Data**: Read pre-prepared CSV file with image paths and labels\n2. **Split Dataset**: 70% train, 15% validation, 15% test\n3. **Data Augmentation**: Apply transforms for training robustness\n4. **Model**: VGG19 pre-trained on ImageNet, fine-tuned for binary classification\n5. **Hyperparameter Tuning**: Use Optuna to find best parameters\n6. **Training**: Train final model with best hyperparameters\n7. **Evaluation**: Test set metrics and visualizations\n\n### Requirements:\n- Google Colab with GPU runtime\n- `post_impressionism_data.csv` file (created by Get_Post_Impressionism_Data.ipynb)\n- Weights & Biases account for experiment tracking\n\n---\n","metadata":{"id":"8h8XmJVfP-A8"}},{"cell_type":"markdown","source":"## 1. Environment Setup\n","metadata":{"id":"8iQGUIlOP-A-"}},{"cell_type":"code","source":"# Check if running on Google Colab\nimport sys\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"âœ“ Running on Google Colab\")\nelse:\n    print(\"Running locally\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DQqOcR7cP-A_","outputId":"9d920786-7eeb-469c-8298-7ab7119792f4","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:12:38.431501Z","iopub.execute_input":"2026-01-04T06:12:38.432253Z","iopub.status.idle":"2026-01-04T06:12:38.439570Z","shell.execute_reply.started":"2026-01-04T06:12:38.432221Z","shell.execute_reply":"2026-01-04T06:12:38.438842Z"}},"outputs":[{"name":"stdout","text":"Running locally\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Install required packages: optuna (hyperparameter tuning), wandb (experiment tracking)\n%pip install -q optuna wandb\n","metadata":{"id":"T-wFi03lP-BA","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:12:41.118101Z","iopub.execute_input":"2026-01-04T06:12:41.118457Z","iopub.status.idle":"2026-01-04T06:12:46.728279Z","shell.execute_reply.started":"2026-01-04T06:12:41.118429Z","shell.execute_reply":"2026-01-04T06:12:46.727583Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 2. Import Libraries\n","metadata":{"id":"Zj0h6Pw0P-BC"}},{"cell_type":"code","source":"# Import libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nfrom tqdm import tqdm\n\n# PyTorch\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\n\n# Scikit-learn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, accuracy_score,\n    precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n)\n\n# Hyperparameter tuning and logging\nimport optuna\nimport wandb\n\n# Set random seeds for reproducibility\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n","metadata":{"id":"S8aoyWL1P-BF","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:13:12.152304Z","iopub.execute_input":"2026-01-04T06:13:12.152741Z","iopub.status.idle":"2026-01-04T06:13:12.160687Z","shell.execute_reply.started":"2026-01-04T06:13:12.152717Z","shell.execute_reply":"2026-01-04T06:13:12.159963Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.8.0+cu126\nCUDA available: True\nGPU: Tesla T4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Setup device (GPU/CPU) - GPU is much faster for training\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nif device.type == 'cpu':\n    print(\"âš ï¸ WARNING: Running on CPU. Enable GPU in Colab: Runtime -> Change runtime type -> GPU\")\n","metadata":{"id":"4NTjxVeHP-BO","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:13:16.586183Z","iopub.execute_input":"2026-01-04T06:13:16.586830Z","iopub.status.idle":"2026-01-04T06:13:16.591776Z","shell.execute_reply.started":"2026-01-04T06:13:16.586794Z","shell.execute_reply":"2026-01-04T06:13:16.590864Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Login to Weights & Biases for experiment tracking\nwandb.login(key=\"16d1bc863b28f81253ac0ee253b453393791a7e1\")\nprint(\"âœ“ Logged in to Weights & Biases\")\n","metadata":{"id":"96eF9IOzP-BP","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:13:26.852843Z","iopub.execute_input":"2026-01-04T06:13:26.853228Z","iopub.status.idle":"2026-01-04T06:13:26.953566Z","shell.execute_reply.started":"2026-01-04T06:13:26.853205Z","shell.execute_reply":"2026-01-04T06:13:26.952891Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"âœ“ Logged in to Weights & Biases\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"## 3. Data Preparation\n","metadata":{"id":"PylwidTjP-BP"}},{"cell_type":"code","source":"# Scan Post_Impressionism directory and create metadata CSV\nimport os\nimport pandas as pd\n\n# Find Post_Impressionism directory (works in both Kaggle and Colab)\npossible_dirs = [\n    \"/kaggle/input/wikiart/Post_Impressionism\",  # Kaggle\n    \"/content/data/Post_Impressionism\",          # Colab\n    \"/content/Post_Impressionism\",               # Colab alternative\n    \"/content/wikiart/Post_Impressionism\",       # Colab alternative\n]\n\nbase_dir = None\nfor dir_path in possible_dirs:\n    if os.path.exists(dir_path):\n        base_dir = dir_path\n        break\n\nif base_dir is None:\n    raise FileNotFoundError(\n        f\"âŒ Post_Impressionism directory not found!\\n\"\n        f\"   Checked: {possible_dirs}\\n\"\n        f\"   Please download images to one of these locations.\"\n    )\n\nprint(f\"âœ“ Found images in: {base_dir}\")\n\n# Scan directory and create DataFrame (like Nir)\nrecords = []\nfor fname in os.listdir(base_dir):\n    if not fname.lower().endswith((\".jpg\", \".png\")):\n        continue\n    \n    artist = fname.split(\"_\")[0]  # Extract artist name from filename\n    \n    records.append({\n        \"filepath\": os.path.join(base_dir, fname),\n        \"filename\": fname,\n        \"artist\": artist,\n        \"is_van_gogh\": 1 if \"van-gogh\" in artist.lower() else 0\n    })\n\ndf = pd.DataFrame(records)\n\n# Save metadata to CSV\ncsv_output_path = \"/kaggle/working/post_impressionism_data.csv\" if os.path.exists(\"/kaggle\") else (\"/content/post_impressionism_data.csv\" if IN_COLAB else \"post_impressionism_data.csv\")\ndf.to_csv(csv_output_path, index=False)\nprint(f\"âœ“ Saved metadata CSV: {csv_output_path}\")\n\nprint(f\"\\nâœ“ Loaded: {len(df)} images\")\nprint(f\"  Van Gogh: {df['is_van_gogh'].sum()}\")\nprint(f\"  Other: {len(df) - df['is_van_gogh'].sum()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:13:30.537451Z","iopub.execute_input":"2026-01-04T06:13:30.537755Z","iopub.status.idle":"2026-01-04T06:13:31.033657Z","shell.execute_reply.started":"2026-01-04T06:13:30.537723Z","shell.execute_reply":"2026-01-04T06:13:31.033027Z"}},"outputs":[{"name":"stdout","text":"âœ“ Found images in: /kaggle/input/wikiart/Post_Impressionism\nâœ“ Saved metadata CSV: /kaggle/working/post_impressionism_data.csv\n\nâœ“ Loaded: 6450 images\n  Van Gogh: 1005\n  Other: 5445\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Split dataset: 70% train, 15% validation, 15% test (stratified to maintain class balance)\ntrain_df, temp_df = train_test_split(\n    df, test_size=0.3, stratify=df[\"is_van_gogh\"], random_state=SEED\n)\n\nval_df, test_df = train_test_split(\n    temp_df, test_size=0.5, stratify=temp_df[\"is_van_gogh\"], random_state=SEED\n)\n\nprint(\"Dataset splits:\")\nprint(f\"  Train: {len(train_df):5d} ({len(train_df)/len(df):.1%})\")\nprint(f\"  Val:   {len(val_df):5d} ({len(val_df)/len(df):.1%})\")\nprint(f\"  Test:  {len(test_df):5d} ({len(test_df)/len(df):.1%})\")\n\nprint(\"\\nClass distribution:\")\nprint(f\"  Train - Van Gogh: {train_df['is_van_gogh'].mean():.2%}\")\nprint(f\"  Val   - Van Gogh: {val_df['is_van_gogh'].mean():.2%}\")\nprint(f\"  Test  - Van Gogh: {test_df['is_van_gogh'].mean():.2%}\")\n","metadata":{"id":"pLShT63aP-BR","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:13:40.260268Z","iopub.execute_input":"2026-01-04T06:13:40.260640Z","iopub.status.idle":"2026-01-04T06:13:40.307262Z","shell.execute_reply.started":"2026-01-04T06:13:40.260608Z","shell.execute_reply":"2026-01-04T06:13:40.306440Z"}},"outputs":[{"name":"stdout","text":"Dataset splits:\n  Train:  4515 (70.0%)\n  Val:     967 (15.0%)\n  Test:    968 (15.0%)\n\nClass distribution:\n  Train - Van Gogh: 15.59%\n  Val   - Van Gogh: 15.51%\n  Test  - Van Gogh: 15.60%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## 4. Data Transforms & Dataset Class\n","metadata":{"id":"hwqo_KbRP-BS"}},{"cell_type":"code","source":"# Define image transforms: resize to 224x224, normalize with ImageNet stats\nIMAGENET_MEAN = [0.485, 0.456, 0.406]\nIMAGENET_STD = [0.229, 0.224, 0.225]\n\n# Training: data augmentation (random crop, flip, rotation, color jitter)\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n])\n\n# Evaluation: no augmentation (consistent evaluation)\neval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n])\n\nprint(\"Transforms defined âœ“\")\n","metadata":{"id":"RSzBqFT7P-BS","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:13:44.660284Z","iopub.execute_input":"2026-01-04T06:13:44.660992Z","iopub.status.idle":"2026-01-04T06:13:44.666794Z","shell.execute_reply.started":"2026-01-04T06:13:44.660964Z","shell.execute_reply":"2026-01-04T06:13:44.666267Z"}},"outputs":[{"name":"stdout","text":"Transforms defined âœ“\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Custom PyTorch Dataset class to load images from file paths\nclass VanGoghDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        # Filter out files that don't exist\n        self.df = self.df[self.df['filepath'].apply(os.path.exists)].reset_index(drop=True)\n        if len(self.df) < len(df):\n            print(f\"âš ï¸ Warning: {len(df) - len(self.df)} files not found and removed\")\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        try:\n            image = Image.open(row[\"filepath\"]).convert(\"RGB\")\n            label = row[\"is_van_gogh\"]\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n        except Exception as e:\n            print(f\"Error loading {row['filepath']}: {e}\")\n            # Return a black image as fallback (shouldn't happen if we filtered)\n            image = Image.new('RGB', (224, 224), color='black')\n            label = row[\"is_van_gogh\"]\n            if self.transform:\n                image = self.transform(image)\n            return image, label\n\n# Create datasets\ntrain_dataset = VanGoghDataset(train_df, transform=train_transform)\nval_dataset = VanGoghDataset(val_df, transform=eval_transform)\ntest_dataset = VanGoghDataset(test_df, transform=eval_transform)\n\nprint(f\"Datasets: Train={len(train_dataset)}, Val={len(val_dataset)}, Test={len(test_dataset)}\")\n","metadata":{"id":"TXFfgteAP-BS","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:14:21.688996Z","iopub.execute_input":"2026-01-04T06:14:21.689235Z","iopub.status.idle":"2026-01-04T06:14:29.073151Z","shell.execute_reply.started":"2026-01-04T06:14:21.689213Z","shell.execute_reply":"2026-01-04T06:14:29.072347Z"}},"outputs":[{"name":"stdout","text":"Datasets: Train=4515, Val=967, Test=968\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## 5. Training Functions\n","metadata":{"id":"bccCmJABP-BT"}},{"cell_type":"code","source":"# Training and evaluation functions\ndef train_one_epoch(model, loader, optimizer, criterion, device):\n    \"\"\"Train for one epoch: forward pass, compute loss, backward pass, update weights\"\"\"\n    model.train()\n    total_loss = 0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        if wandb.run is not None:\n            wandb.log({\"batch_loss\": loss.item()})\n    return total_loss / len(loader)\n\n@torch.no_grad()\ndef eval_one_epoch(model, loader, criterion, device):\n    \"\"\"Evaluate: forward pass only, compute loss and accuracy\"\"\"\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        total_loss += loss.item()\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    return total_loss / len(loader), correct / total\n\nprint(\"Training functions defined âœ“\")\n","metadata":{"id":"lk0j02iOP-BT","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:14:35.693764Z","iopub.execute_input":"2026-01-04T06:14:35.694086Z","iopub.status.idle":"2026-01-04T06:14:35.702478Z","shell.execute_reply.started":"2026-01-04T06:14:35.694057Z","shell.execute_reply":"2026-01-04T06:14:35.701723Z"}},"outputs":[{"name":"stdout","text":"Training functions defined âœ“\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 6. Hyperparameter Tuning with Optuna\n","metadata":{"id":"AeGOP6L1P-BT"}},{"cell_type":"code","source":"# Create model: supports both VGG19 and AlexNet (project requirement)\ndef create_model(model_name='VGG19', freeze_features=True, dropout=0.5):\n    \"\"\"\n    Create model with binary classifier.\n    \n    Args:\n        model_name: 'VGG19' or 'AlexNet'\n        freeze_features: If True, freeze feature extractor (only train classifier)\n        dropout: Dropout rate for classifier (0.0 to 0.7)\n    \"\"\"\n    if model_name == 'VGG19':\n        model = models.vgg19(weights='IMAGENET1K_V1')\n        if freeze_features:\n            for param in model.features.parameters():\n                param.requires_grad = False\n        # Modify classifier: VGG19 classifier[6] is the last Linear layer\n        num_features = model.classifier[6].in_features\n        model.classifier[6] = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(num_features, 2)  # Binary classification\n        )\n    elif model_name == 'AlexNet':\n        model = models.alexnet(weights='IMAGENET1K_V1')\n        if freeze_features:\n            for param in model.features.parameters():\n                param.requires_grad = False\n        # Modify classifier: AlexNet classifier[6] is the last Linear layer\n        num_features = model.classifier[6].in_features\n        model.classifier[6] = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(num_features, 2)  # Binary classification\n        )\n    else:\n        raise ValueError(f\"Unknown model: {model_name}\")\n    \n    return model.to(device)\n\ndef objective(trial):\n    \"\"\"Optuna objective: try hyperparameters, train model, return validation accuracy\"\"\"\n    # Optuna suggests hyperparameters\n    model_name = trial.suggest_categorical(\"model_name\", [\"VGG19\", \"AlexNet\"])  # Project requirement: both models\n    lr = trial.suggest_float(\"lr\", 1e-5, 5e-4, log=True)  # Reduced max LR for stability (was 1e-2)\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"AdamW\"])\n    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])  # Added 8 for smaller GPUs\n    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n    momentum = trial.suggest_float(\"momentum\", 0.8, 0.99) if optimizer_name == \"SGD\" else 0.0\n    freeze_features = trial.suggest_categorical(\"freeze_features\", [True, False])\n    dropout = trial.suggest_float(\"dropout\", 0.0, 0.7)  # Added dropout search\n\n    # Create DataLoaders, model, optimizer\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)  # Like Nir\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n\n    run = wandb.init(\n        project=\"VanGogh_Classifier\",\n        name=f\"trial_{trial.number}_{model_name}\",\n        config={\"model_name\": model_name, \"lr\": lr, \"optimizer\": optimizer_name, \"batch_size\": batch_size,\n                \"weight_decay\": weight_decay, \"momentum\": momentum,\n                \"freeze_features\": freeze_features, \"dropout\": dropout},\n        reinit=True\n    )\n\n    model = create_model(model_name=model_name, freeze_features=freeze_features, dropout=dropout)\n    criterion = nn.CrossEntropyLoss()\n    trainable_params = filter(lambda p: p.requires_grad, model.parameters())\n\n    if optimizer_name == \"SGD\":\n        optimizer = torch.optim.SGD(trainable_params, lr=lr, momentum=momentum, weight_decay=weight_decay)\n    elif optimizer_name == \"AdamW\":\n        optimizer = torch.optim.AdamW(trainable_params, lr=lr, weight_decay=weight_decay)\n    else:\n        optimizer = torch.optim.Adam(trainable_params, lr=lr, weight_decay=weight_decay)\n\n    # Train for a few epochs (quick evaluation for hyperparameter search)\n    num_epochs = 3  # Reduced for faster trials (30-60 min total search time)\n    best_val_acc = 0.0\n    for epoch in range(num_epochs):\n        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n        val_loss, val_acc = eval_one_epoch(model, val_loader, criterion, device)\n        best_val_acc = max(best_val_acc, val_acc)\n        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss,\n                   \"val_acc\": val_acc, \"best_val_acc\": best_val_acc})\n        trial.report(val_acc, epoch)\n        if trial.should_prune():  # Stop bad trials early\n            run.finish()\n            raise optuna.exceptions.TrialPruned()\n    run.finish()\n    return best_val_acc\n\nprint(\"Optuna objective function defined âœ“ (supports VGG19 and AlexNet)\")\n","metadata":{"id":"NoopVVlgP-BT","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:14:39.489343Z","iopub.execute_input":"2026-01-04T06:14:39.489658Z","iopub.status.idle":"2026-01-04T06:14:39.501875Z","shell.execute_reply.started":"2026-01-04T06:14:39.489634Z","shell.execute_reply":"2026-01-04T06:14:39.501150Z"}},"outputs":[{"name":"stdout","text":"Optuna objective function defined âœ“ (supports VGG19 and AlexNet)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Run hyperparameter search with Optuna\n# Project requirement: must take at least 30 minutes, max 60 minutes\nimport optuna  # Ensure optuna is imported (in case cells run out of order)\nimport time\n\nprint(\"Starting hyperparameter search...\")\nprint(\"=\"*60)\n\nstudy = optuna.create_study(\n    direction=\"maximize\",\n    pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=2)\n)\n\n# Track start time\nstart_time = time.time()\n\n# Run optimization (max 60 minutes - will stop at timeout)\nstudy.optimize(objective, n_trials=10, timeout=3600, show_progress_bar=True)  # 10 trials for 30-60 min window\n\n# Calculate elapsed time\nelapsed_time = time.time() - start_time\nelapsed_minutes = elapsed_time / 60\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"HYPERPARAMETER SEARCH COMPLETE!\")\nprint(\"=\"*60)\nprint(f\"\\nâ±ï¸  Time taken: {elapsed_minutes:.2f} minutes ({elapsed_time:.0f} seconds)\")\nprint(f\"ğŸ“Š Completed trials: {len(study.trials)} / 10\")\n\n# Check project requirements\nif elapsed_minutes < 30:\n    print(f\"\\nâš ï¸  WARNING: Search took only {elapsed_minutes:.2f} minutes!\")\n    print(\"   Project requires at least 30 minutes. Consider increasing n_trials.\")\nelif elapsed_minutes > 60:\n    print(f\"\\nâš ï¸  WARNING: Search took {elapsed_minutes:.2f} minutes (exceeded 60 min limit)\")\nelse:\n    print(f\"\\nâœ“ Time requirement met: {elapsed_minutes:.2f} minutes (30-60 min range)\")\n\nprint(f\"\\nBest validation accuracy: {study.best_value:.4f}\")\nprint(f\"\\nBest hyperparameters:\")\nfor key, value in study.best_params.items():\n    print(f\"  {key}: {value}\")\n","metadata":{"id":"6T2jcKusP-BU","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T06:14:52.798839Z","iopub.execute_input":"2026-01-04T06:14:52.799192Z","iopub.status.idle":"2026-01-04T07:10:51.055671Z","shell.execute_reply.started":"2026-01-04T06:14:52.799168Z","shell.execute_reply":"2026-01-04T07:10:51.054758Z"}},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2026-01-04 06:14:52,803]\u001b[0m A new study created in memory with name: no-name-b1538f1a-0a57-4ad8-98a4-96917bf1132d\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Starting hyperparameter search...\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/optuna/progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n  self._init_valid()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4438eb45cd214317be863dce50c32121"}},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_061452-xwkgd6wa</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/xwkgd6wa' target=\"_blank\">trial_0_VGG19</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/xwkgd6wa' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/xwkgd6wa</a>"},"metadata":{}},{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n","output_type":"stream"},{"name":"stderr","text":"\n  0%|          | 0.00/548M [00:00<?, ?B/s]\u001b[A\n  2%|â–         | 11.4M/548M [00:00<00:04, 119MB/s]\u001b[A\n  5%|â–Œ         | 29.6M/548M [00:00<00:03, 161MB/s]\u001b[A\n  9%|â–‰         | 50.6M/548M [00:00<00:02, 188MB/s]\u001b[A\n 13%|â–ˆâ–        | 71.4M/548M [00:00<00:02, 200MB/s]\u001b[A\n 17%|â–ˆâ–‹        | 94.5M/548M [00:00<00:02, 215MB/s]\u001b[A\n 21%|â–ˆâ–ˆâ–       | 118M/548M [00:00<00:02, 224MB/s] \u001b[A\n 25%|â–ˆâ–ˆâ–Œ       | 139M/548M [00:00<00:01, 221MB/s]\u001b[A\n 29%|â–ˆâ–ˆâ–‰       | 160M/548M [00:00<00:01, 208MB/s]\u001b[A\n 33%|â–ˆâ–ˆâ–ˆâ–      | 182M/548M [00:00<00:01, 213MB/s]\u001b[A\n 37%|â–ˆâ–ˆâ–ˆâ–‹      | 202M/548M [00:01<00:01, 206MB/s]\u001b[A\n 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 226M/548M [00:01<00:01, 217MB/s]\u001b[A\n 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 246M/548M [00:01<00:01, 217MB/s]\u001b[A\n 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 269M/548M [00:01<00:01, 223MB/s]\u001b[A\n 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 291M/548M [00:01<00:01, 213MB/s]\u001b[A\n 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 311M/548M [00:01<00:01, 207MB/s]\u001b[A\n 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 331M/548M [00:01<00:01, 203MB/s]\u001b[A\n 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 350M/548M [00:01<00:01, 197MB/s]\u001b[A\n 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 370M/548M [00:01<00:00, 201MB/s]\u001b[A\n 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 394M/548M [00:01<00:00, 213MB/s]\u001b[A\n 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 417M/548M [00:02<00:00, 221MB/s]\u001b[A\n 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 438M/548M [00:02<00:00, 220MB/s]\u001b[A\n 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 459M/548M [00:02<00:00, 212MB/s]\u001b[A\n 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 480M/548M [00:02<00:00, 214MB/s]\u001b[A\n 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 501M/548M [00:02<00:00, 216MB/s]\u001b[A\n 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 525M/548M [00:02<00:00, 224MB/s]\u001b[A\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548M/548M [00:02<00:00, 212MB/s]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–„â–„â–ˆâ–ƒâ–‚â–‚â–ƒâ–â–‚â–…â–ƒâ–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–‚â–‚â–â–„â–ƒâ–„â–ƒâ–â–‚â–ƒâ–„â–„â–â–ƒâ–â–‚â–ƒâ–‚â–‡â–â–†â–ƒ</td></tr><tr><td>best_val_acc</td><td>â–â–„â–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–â–„â–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.29169</td></tr><tr><td>best_val_acc</td><td>0.90176</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.32551</td></tr><tr><td>val_acc</td><td>0.90176</td></tr><tr><td>val_loss</td><td>0.27935</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_0_VGG19</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/xwkgd6wa' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/xwkgd6wa</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_061452-xwkgd6wa/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 06:20:35,775]\u001b[0m Trial 0 finished with value: 0.9017580144777663 and parameters: {'model_name': 'VGG19', 'lr': 0.000173983612452804, 'optimizer': 'SGD', 'batch_size': 16, 'weight_decay': 0.007164448276799248, 'momentum': 0.8733176061424315, 'freeze_features': True, 'dropout': 0.4724207818967166}. Best is trial 0 with value: 0.9017580144777663.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_062035-0bgb2atv</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/0bgb2atv' target=\"_blank\">trial_1_VGG19</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/0bgb2atv' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/0bgb2atv</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–ƒâ–„â–ˆâ–…â–ƒâ–ƒâ–‡â–ƒâ–„â–…â–„â–„â–‚â–ƒâ–‚â–„â–‚â–†â–…â–‚â–…â–‚â–‚â–â–†â–„â–†â–…â–ƒâ–…â–ˆâ–â–‡â–…â–…â–„â–…â–‚â–„â–</td></tr><tr><td>best_val_acc</td><td>â–â–‚â–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–â–‚â–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–ƒâ–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.97241</td></tr><tr><td>best_val_acc</td><td>0.91003</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.31359</td></tr><tr><td>val_acc</td><td>0.91003</td></tr><tr><td>val_loss</td><td>0.25436</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_1_VGG19</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/0bgb2atv' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/0bgb2atv</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_062035-0bgb2atv/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 06:26:00,514]\u001b[0m Trial 1 finished with value: 0.9100310237849017 and parameters: {'model_name': 'VGG19', 'lr': 0.00013522067463498177, 'optimizer': 'SGD', 'batch_size': 8, 'weight_decay': 0.00018062546336143439, 'momentum': 0.8793771028678168, 'freeze_features': True, 'dropout': 0.544995499251158}. Best is trial 1 with value: 0.9100310237849017.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_062600-flaatkoi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/flaatkoi' target=\"_blank\">trial_2_VGG19</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/flaatkoi' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/flaatkoi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–†â–‚â–‚â–ƒâ–ƒâ–â–„â–ƒâ–‚â–ƒâ–ˆâ–‚â–…â–ƒâ–‚â–„â–â–â–‚â–‡â–„â–‚â–‡â–â–â–ƒâ–„â–â–†â–ƒ</td></tr><tr><td>best_val_acc</td><td>â–â–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–‚â–</td></tr><tr><td>val_acc</td><td>â–‡â–ˆâ–</td></tr><tr><td>val_loss</td><td>â–‚â–â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.33905</td></tr><tr><td>best_val_acc</td><td>0.94105</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.22553</td></tr><tr><td>val_acc</td><td>0.85936</td></tr><tr><td>val_loss</td><td>0.23516</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_2_VGG19</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/flaatkoi' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/flaatkoi</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_062600-flaatkoi/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 06:33:41,755]\u001b[0m Trial 2 finished with value: 0.9410548086866598 and parameters: {'model_name': 'VGG19', 'lr': 4.9828936799803324e-05, 'optimizer': 'Adam', 'batch_size': 8, 'weight_decay': 0.0035487365213557535, 'freeze_features': False, 'dropout': 0.6109768807731137}. Best is trial 2 with value: 0.9410548086866598.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_063341-3cslo6cm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/3cslo6cm' target=\"_blank\">trial_3_VGG19</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/3cslo6cm' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/3cslo6cm</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–‚â–ƒâ–ƒâ–â–â–ƒâ–‚â–‚â–ˆâ–„â–â–ƒâ–â–â–‡â–â–ƒâ–‚â–„â–†â–â–â–â–â–„â–‚â–‚â–‚â–„â–‚â–â–„â–‚â–…â–â–‚â–…â–…â–ƒâ–†</td></tr><tr><td>best_val_acc</td><td>â–â–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–â–ˆâ–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>1.13643</td></tr><tr><td>best_val_acc</td><td>0.92347</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.18933</td></tr><tr><td>val_acc</td><td>0.92347</td></tr><tr><td>val_loss</td><td>0.18894</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_3_VGG19</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/3cslo6cm' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/3cslo6cm</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_063341-3cslo6cm/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 06:39:15,275]\u001b[0m Trial 3 finished with value: 0.9234746639089969 and parameters: {'model_name': 'VGG19', 'lr': 1.732867150351808e-05, 'optimizer': 'AdamW', 'batch_size': 8, 'weight_decay': 1.0004849583868828e-06, 'freeze_features': True, 'dropout': 0.16771561619472625}. Best is trial 2 with value: 0.9410548086866598.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_063915-us0d8hm5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/us0d8hm5' target=\"_blank\">trial_4_VGG19</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/us0d8hm5' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/us0d8hm5</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–ˆâ–†â–‡â–ˆâ–‡â–…â–†â–†â–„â–†â–…â–‚â–„â–…â–†â–„â–‚â–„â–„â–‚â–‚â–‚â–…â–…â–„â–ƒâ–ƒâ–ƒâ–†â–‚â–‡â–â–â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚</td></tr><tr><td>best_val_acc</td><td>â–â–â–</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–ˆâ–‡â–</td></tr><tr><td>val_loss</td><td>â–ˆâ–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.09171</td></tr><tr><td>best_val_acc</td><td>0.92141</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.18342</td></tr><tr><td>val_acc</td><td>0.909</td></tr><tr><td>val_loss</td><td>0.19792</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_4_VGG19</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/us0d8hm5' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/us0d8hm5</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_063915-us0d8hm5/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 06:45:14,834]\u001b[0m Trial 4 finished with value: 0.921406411582213 and parameters: {'model_name': 'VGG19', 'lr': 0.0001077562658830961, 'optimizer': 'Adam', 'batch_size': 64, 'weight_decay': 0.0001132482778210956, 'freeze_features': False, 'dropout': 0.4127686438899352}. Best is trial 2 with value: 0.9410548086866598.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_064514-88syxb1z</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/88syxb1z' target=\"_blank\">trial_5_AlexNet</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/88syxb1z' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/88syxb1z</a>"},"metadata":{}},{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","output_type":"stream"},{"name":"stderr","text":"\n  0%|          | 0.00/233M [00:00<?, ?B/s]\u001b[A\n  3%|â–         | 7.25M/233M [00:00<00:03, 75.9MB/s]\u001b[A\n 13%|â–ˆâ–        | 30.6M/233M [00:00<00:01, 175MB/s] \u001b[A\n 23%|â–ˆâ–ˆâ–       | 54.0M/233M [00:00<00:00, 207MB/s]\u001b[A\n 32%|â–ˆâ–ˆâ–ˆâ–      | 75.0M/233M [00:00<00:00, 212MB/s]\u001b[A\n 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 95.2M/233M [00:00<00:00, 202MB/s]\u001b[A\n 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 115M/233M [00:00<00:00, 199MB/s] \u001b[A\n 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 138M/233M [00:00<00:00, 214MB/s]\u001b[A\n 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 159M/233M [00:00<00:00, 216MB/s]\u001b[A\n 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 182M/233M [00:00<00:00, 224MB/s]\u001b[A\n 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 204M/233M [00:01<00:00, 215MB/s]\u001b[A\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 233M/233M [00:01<00:00, 209MB/s]\u001b[A\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–ˆâ–‚â–‚â–„â–‚â–„â–â–‚â–‚â–‚â–ƒâ–â–â–‚â–…â–â–„â–â–‚â–‚â–â–â–ƒâ–‚â–â–â–‚â–‚â–â–‚â–â–‚â–„â–‚â–â–â–‚â–‚â–…â–‚</td></tr><tr><td>best_val_acc</td><td>â–â–†â–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–â–†â–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>1.65431</td></tr><tr><td>best_val_acc</td><td>0.94209</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.16056</td></tr><tr><td>val_acc</td><td>0.94209</td></tr><tr><td>val_loss</td><td>0.16556</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_5_AlexNet</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/88syxb1z' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/88syxb1z</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_064514-88syxb1z/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 06:50:19,591]\u001b[0m Trial 5 finished with value: 0.9420889348500517 and parameters: {'model_name': 'AlexNet', 'lr': 2.087969996073352e-05, 'optimizer': 'AdamW', 'batch_size': 8, 'weight_decay': 0.008337592219143541, 'freeze_features': False, 'dropout': 0.2876576503003648}. Best is trial 5 with value: 0.9420889348500517.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_065019-n7b0t92s</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/n7b0t92s' target=\"_blank\">trial_6_AlexNet</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/n7b0t92s' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/n7b0t92s</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–ƒâ–ƒâ–‚â–ƒâ–„â–â–‚â–ƒâ–ˆâ–ƒâ–†â–â–„â–â–‚â–â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–‚â–â–â–ƒâ–‚â–â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–„â–â–‚â–…â–</td></tr><tr><td>best_val_acc</td><td>â–â–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–‚â–</td></tr><tr><td>val_acc</td><td>â–ƒâ–ˆâ–</td></tr><tr><td>val_loss</td><td>â–ˆâ–â–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>1.09479</td></tr><tr><td>best_val_acc</td><td>0.89555</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.2913</td></tr><tr><td>val_acc</td><td>0.8728</td></tr><tr><td>val_loss</td><td>0.27379</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_6_AlexNet</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/n7b0t92s' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/n7b0t92s</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_065019-n7b0t92s/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 06:55:20,525]\u001b[0m Trial 6 pruned. \u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_065520-33ct6tmu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/33ct6tmu' target=\"_blank\">trial_7_AlexNet</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/33ct6tmu' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/33ct6tmu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–â–„â–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–â–â–‚â–‚â–ƒâ–‚â–‚â–ƒ</td></tr><tr><td>best_val_acc</td><td>â–â–ˆâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–â–ˆâ–‚</td></tr><tr><td>val_loss</td><td>â–ˆâ–â–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.59956</td></tr><tr><td>best_val_acc</td><td>0.93278</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.16838</td></tr><tr><td>val_acc</td><td>0.92141</td></tr><tr><td>val_loss</td><td>0.18581</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_7_AlexNet</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/33ct6tmu' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/33ct6tmu</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_065520-33ct6tmu/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 07:00:11,437]\u001b[0m Trial 7 finished with value: 0.9327817993795243 and parameters: {'model_name': 'AlexNet', 'lr': 3.5002308061948084e-05, 'optimizer': 'AdamW', 'batch_size': 32, 'weight_decay': 0.002708375096417655, 'freeze_features': False, 'dropout': 0.13032260169549328}. Best is trial 5 with value: 0.9420889348500517.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_070011-2kwsajse</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/2kwsajse' target=\"_blank\">trial_8_AlexNet</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/2kwsajse' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/2kwsajse</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–„â–†â–„â–ˆâ–„â–…â–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–ƒ</td></tr><tr><td>best_val_acc</td><td>â–â–…â–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–â–…â–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–„â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.38921</td></tr><tr><td>best_val_acc</td><td>0.94002</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.1756</td></tr><tr><td>val_acc</td><td>0.94002</td></tr><tr><td>val_loss</td><td>0.15912</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_8_AlexNet</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/2kwsajse' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/2kwsajse</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_070011-2kwsajse/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 07:05:06,801]\u001b[0m Trial 8 finished with value: 0.9400206825232679 and parameters: {'model_name': 'AlexNet', 'lr': 3.1250718474639714e-05, 'optimizer': 'Adam', 'batch_size': 64, 'weight_decay': 1.5478271383065864e-05, 'freeze_features': False, 'dropout': 0.0731424107572473}. Best is trial 5 with value: 0.9420889348500517.\u001b[0m\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_070506-7eonwius</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/7eonwius' target=\"_blank\">trial_9_VGG19</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/7eonwius' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/7eonwius</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–â–ˆâ–…â–â–â–‚â–â–â–…â–…â–„â–â–‚â–ƒâ–ƒâ–‚â–„â–…â–â–‚â–„â–â–â–‚â–…â–†â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–‚â–â–…â–‚â–†</td></tr><tr><td>best_val_acc</td><td>â–â–ƒâ–ˆ</td></tr><tr><td>epoch</td><td>â–â–…â–ˆ</td></tr><tr><td>train_loss</td><td>â–ˆâ–ƒâ–</td></tr><tr><td>val_acc</td><td>â–â–ƒâ–ˆ</td></tr><tr><td>val_loss</td><td>â–ˆâ–„â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.00741</td></tr><tr><td>best_val_acc</td><td>0.92037</td></tr><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.30086</td></tr><tr><td>val_acc</td><td>0.92037</td></tr><tr><td>val_loss</td><td>0.24252</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_9_VGG19</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/7eonwius' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/7eonwius</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_070506-7eonwius/logs</code>"},"metadata":{}},{"name":"stdout","text":"\u001b[32m[I 2026-01-04 07:10:51,047]\u001b[0m Trial 9 finished with value: 0.9203722854188211 and parameters: {'model_name': 'VGG19', 'lr': 0.0003514085025033413, 'optimizer': 'Adam', 'batch_size': 8, 'weight_decay': 8.999196142620435e-05, 'freeze_features': True, 'dropout': 0.2858068361657357}. Best is trial 5 with value: 0.9420889348500517.\u001b[0m\n\n============================================================\nHYPERPARAMETER SEARCH COMPLETE!\n============================================================\n\nâ±ï¸  Time taken: 55.97 minutes (3358 seconds)\nğŸ“Š Completed trials: 10 / 10\n\nâœ“ Time requirement met: 55.97 minutes (30-60 min range)\n\nBest validation accuracy: 0.9421\n\nBest hyperparameters:\n  model_name: AlexNet\n  lr: 2.087969996073352e-05\n  optimizer: AdamW\n  batch_size: 8\n  weight_decay: 0.008337592219143541\n  freeze_features: False\n  dropout: 0.2876576503003648\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## 7. Train Final Model\n","metadata":{"id":"JM7K6ZYQP-BV"}},{"cell_type":"code","source":"# Train final model with best hyperparameters\nbest_params = study.best_params\nprint(\"Training final model with best parameters:\")\nfor k, v in best_params.items():\n    print(f\"  {k}: {v}\")\n\n# Setup: DataLoaders, model, optimizer, scheduler\nfinal_train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True, num_workers=2)\nfinal_val_loader = DataLoader(val_dataset, batch_size=best_params['batch_size'], shuffle=False, num_workers=2)\n\nfinal_model = create_model(\n    model_name=best_params.get('model_name', 'VGG19'),\n    freeze_features=best_params.get('freeze_features', False),\n    dropout=best_params.get('dropout', 0.5)\n)\ncriterion = nn.CrossEntropyLoss()\ntrainable_params = filter(lambda p: p.requires_grad, final_model.parameters())\n\nif best_params['optimizer'] == \"SGD\":\n    final_optimizer = torch.optim.SGD(trainable_params, lr=best_params['lr'],\n                                       momentum=best_params.get('momentum', 0.9),\n                                       weight_decay=best_params.get('weight_decay', 1e-4))\nelif best_params['optimizer'] == \"AdamW\":\n    final_optimizer = torch.optim.AdamW(trainable_params, lr=best_params['lr'],\n                                         weight_decay=best_params.get('weight_decay', 1e-4))\nelse:\n    final_optimizer = torch.optim.Adam(trainable_params, lr=best_params['lr'],\n                                        weight_decay=best_params.get('weight_decay', 1e-4))\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(final_optimizer, mode='max', factor=0.5, patience=3)\n\n# Training loop with early stopping\nrun = wandb.init(project=\"VanGogh_Classifier\", name=\"final_model_training\",\n                 config={**best_params, \"training_type\": \"final\"}, reinit=True)\n\nnum_epochs = 15  # Reduced for time efficiency\nbest_val_acc = 0.0\nbest_model_state = None\npatience = 3  # Early stopping patience\nepochs_without_improvement = 0\ntrain_losses, val_losses, val_accuracies = [], [], []\n\nprint(\"\\nStarting training...\")\nprint(\"=\"*60)\n\nfor epoch in range(num_epochs):\n    train_loss = train_one_epoch(final_model, final_train_loader, final_optimizer, criterion, device)\n    val_loss, val_acc = eval_one_epoch(final_model, final_val_loader, criterion, device)\n\n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n\n    scheduler.step(val_acc)\n    wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"val_loss\": val_loss,\n               \"val_acc\": val_acc, \"lr\": final_optimizer.param_groups[0]['lr']})\n\n    print(f\"Epoch {epoch+1:02d}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        best_model_state = {k: v.cpu().clone() for k, v in final_model.state_dict().items()}\n        epochs_without_improvement = 0\n        print(f\"  âœ“ New best model! (Val Acc: {best_val_acc:.4f})\")\n    else:\n        epochs_without_improvement += 1\n\n    if epochs_without_improvement >= patience:\n        print(f\"\\nEarly stopping after {epoch+1} epochs\")\n        break\n\nfinal_model.load_state_dict(best_model_state)\nprint(f\"\\n{'='*60}\")\nprint(f\"Training complete! Best validation accuracy: {best_val_acc:.4f}\")\n\ntorch.save({'model_state_dict': best_model_state, 'best_params': best_params,\n            'best_val_acc': best_val_acc}, 'best_vangogh_classifier.pth')\nprint(\"Model saved to 'best_vangogh_classifier.pth'\")\n\nrun.finish()\n","metadata":{"id":"6Y6f0EkbP-BV","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T07:30:33.425035Z","iopub.execute_input":"2026-01-04T07:30:33.425658Z","iopub.status.idle":"2026-01-04T07:47:05.170656Z","shell.execute_reply.started":"2026-01-04T07:30:33.425631Z","shell.execute_reply":"2026-01-04T07:47:05.169902Z"}},"outputs":[{"name":"stdout","text":"Training final model with best parameters:\n  model_name: AlexNet\n  lr: 2.087969996073352e-05\n  optimizer: AdamW\n  batch_size: 8\n  weight_decay: 0.008337592219143541\n  freeze_features: False\n  dropout: 0.2876576503003648\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260104_073034-r3ohxhff</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/r3ohxhff' target=\"_blank\">final_model_training</a></strong> to <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/r3ohxhff' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/r3ohxhff</a>"},"metadata":{}},{"name":"stdout","text":"\nStarting training...\n============================================================\nEpoch 01/15 | Train Loss: 0.2934 | Val Loss: 0.2189 | Val Acc: 0.9173\n  âœ“ New best model! (Val Acc: 0.9173)\nEpoch 02/15 | Train Loss: 0.2035 | Val Loss: 0.1954 | Val Acc: 0.9142\nEpoch 03/15 | Train Loss: 0.1695 | Val Loss: 0.1647 | Val Acc: 0.9359\n  âœ“ New best model! (Val Acc: 0.9359)\nEpoch 04/15 | Train Loss: 0.1353 | Val Loss: 0.1890 | Val Acc: 0.9338\nEpoch 05/15 | Train Loss: 0.1271 | Val Loss: 0.1886 | Val Acc: 0.9204\nEpoch 06/15 | Train Loss: 0.1077 | Val Loss: 0.1427 | Val Acc: 0.9421\n  âœ“ New best model! (Val Acc: 0.9421)\nEpoch 07/15 | Train Loss: 0.0950 | Val Loss: 0.1609 | Val Acc: 0.9431\n  âœ“ New best model! (Val Acc: 0.9431)\nEpoch 08/15 | Train Loss: 0.0770 | Val Loss: 0.2268 | Val Acc: 0.9121\nEpoch 09/15 | Train Loss: 0.0781 | Val Loss: 0.1415 | Val Acc: 0.9421\nEpoch 10/15 | Train Loss: 0.0650 | Val Loss: 0.1533 | Val Acc: 0.9380\n\nEarly stopping after 10 epochs\n\n============================================================\nTraining complete! Best validation accuracy: 0.9431\nModel saved to 'best_vangogh_classifier.pth'\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–â–‚â–â–â–ˆâ–â–ƒâ–â–â–‚â–ƒâ–â–â–â–â–â–â–ƒâ–ƒâ–‚â–ƒâ–â–â–â–â–â–â–„â–â–â–â–</td></tr><tr><td>epoch</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ</td></tr><tr><td>lr</td><td>â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>train_loss</td><td>â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–â–â–</td></tr><tr><td>val_acc</td><td>â–‚â–â–†â–†â–ƒâ–ˆâ–ˆâ–â–ˆâ–‡</td></tr><tr><td>val_loss</td><td>â–‡â–…â–ƒâ–…â–…â–â–ƒâ–ˆâ–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.0337</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>lr</td><td>2e-05</td></tr><tr><td>train_loss</td><td>0.06502</td></tr><tr><td>val_acc</td><td>0.93795</td></tr><tr><td>val_loss</td><td>0.15331</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">final_model_training</strong> at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/r3ohxhff' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier/runs/r3ohxhff</a><br> View project at: <a href='https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/avitalkras-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260104_073034-r3ohxhff/logs</code>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## 8. Visualizations\n","metadata":{"id":"q-ko9yReP-BW"}},{"cell_type":"code","source":"# Plot training curves\nimport matplotlib.pyplot as plt \n    \nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\naxes[0].plot(train_losses, label='Train Loss', color='#1f77b4', linewidth=2)\naxes[0].plot(val_losses, label='Validation Loss', color='#ff7f0e', linewidth=2)\naxes[0].set_xlabel('Epoch')\naxes[0].set_ylabel('Loss')\naxes[0].set_title('Training and Validation Loss', fontweight='bold')\naxes[0].legend()\naxes[0].grid(True, alpha=0.3)\n\naxes[1].plot(val_accuracies, label='Validation Accuracy', color='#2ca02c', linewidth=2, marker='o')\naxes[1].axhline(y=best_val_acc, color='r', linestyle='--', label=f'Best: {best_val_acc:.4f}')\naxes[1].set_xlabel('Epoch')\naxes[1].set_ylabel('Accuracy')\naxes[1].set_title('Validation Accuracy', fontweight='bold')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('training_curves.png', dpi=150)\nplt.show()\nprint(\"Saved: training_curves.png\")\n","metadata":{"id":"ErWsvIAaP-BW","trusted":true,"execution":{"iopub.status.busy":"2026-01-04T17:43:12.165908Z","iopub.execute_input":"2026-01-04T17:43:12.166257Z","iopub.status.idle":"2026-01-04T17:43:12.176633Z","shell.execute_reply.started":"2026-01-04T17:43:12.166228Z","shell.execute_reply":"2026-01-04T17:43:12.175652Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3026502436.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check if training variables exist (step 7 must be run first)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'train_losses'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'val_losses'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'val_accuracies'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'best_val_acc'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     raise NameError(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;34m\"âŒ Training variables not found!\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;34m\"   Please run Step 7 (Train Final Model) first before plotting.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: âŒ Training variables not found!\n   Please run Step 7 (Train Final Model) first before plotting.\n   The variables 'train_losses', 'val_losses', 'val_accuracies', and 'best_val_acc' are created during training in Step 7."],"ename":"NameError","evalue":"âŒ Training variables not found!\n   Please run Step 7 (Train Final Model) first before plotting.\n   The variables 'train_losses', 'val_losses', 'val_accuracies', and 'best_val_acc' are created during training in Step 7.","output_type":"error"}],"execution_count":3},{"cell_type":"markdown","source":"## 9. Test Set Evaluation\n","metadata":{"id":"fZs0WVCpP-BX"}},{"cell_type":"code","source":"# Evaluate on test set (final performance metric)\ntest_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'], shuffle=False, num_workers=2)\n\nfinal_model.eval()\nall_preds, all_labels, all_probs = [], [], []\n\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n        images, labels = images.to(device), labels.to(device)\n        outputs = final_model(images)\n        probs = torch.softmax(outputs, dim=1)\n        preds = outputs.argmax(dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n        all_probs.extend(probs[:, 1].cpu().numpy())\n\nall_preds, all_labels, all_probs = np.array(all_preds), np.array(all_labels), np.array(all_probs)\n\n# Calculate metrics\ntest_accuracy = accuracy_score(all_labels, all_preds)\ntest_precision = precision_score(all_labels, all_preds)\ntest_recall = recall_score(all_labels, all_preds)\ntest_f1 = f1_score(all_labels, all_preds)\ntest_auc = roc_auc_score(all_labels, all_probs)\n\nprint(\"=\"*60)\nprint(\"TEST SET RESULTS\")\nprint(\"=\"*60)\nprint(f\"\\nğŸ“Š Metrics:\")\nprint(f\"   Accuracy:  {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\nprint(f\"   Precision: {test_precision:.4f}\")\nprint(f\"   Recall:    {test_recall:.4f}\")\nprint(f\"   F1-Score:  {test_f1:.4f}\")\nprint(f\"   AUC-ROC:   {test_auc:.4f}\")\n\nprint(f\"\\nğŸ“‹ Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=['Not Van Gogh', 'Van Gogh']))\n","metadata":{"id":"u8M_t2gMP-BX"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Confusion Matrix and ROC Curve\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\ncm = confusion_matrix(all_labels, all_preds)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n            xticklabels=['Not Van Gogh', 'Van Gogh'],\n            yticklabels=['Not Van Gogh', 'Van Gogh'], annot_kws={'size': 14})\naxes[0].set_xlabel('Predicted')\naxes[0].set_ylabel('Actual')\naxes[0].set_title('Confusion Matrix', fontweight='bold')\n\nfpr, tpr, _ = roc_curve(all_labels, all_probs)\naxes[1].plot(fpr, tpr, color='#1f77b4', linewidth=2, label=f'ROC (AUC = {test_auc:.4f})')\naxes[1].plot([0, 1], [0, 1], color='gray', linestyle='--')\naxes[1].fill_between(fpr, tpr, alpha=0.2, color='#1f77b4')\naxes[1].set_xlabel('False Positive Rate')\naxes[1].set_ylabel('True Positive Rate')\naxes[1].set_title('ROC Curve', fontweight='bold')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('confusion_matrix_roc.png', dpi=150)\nplt.show()\nprint(\"Saved: confusion_matrix_roc.png\")\n","metadata":{"id":"R-_b18W6P-BX"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize False Positives (images predicted as Van Gogh but are not)\n# This is important for analysis in Part 3\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Find False Positives\nfalse_positives = []\nfor idx, (pred, label, prob) in enumerate(zip(all_preds, all_labels, all_probs)):\n    if pred == 1 and label == 0:  # Predicted Van Gogh but is not\n        false_positives.append((idx, prob))\n\n# Sort by confidence (highest probability first)\nfalse_positives.sort(key=lambda x: x[1], reverse=True)\n\n# Display top False Positives\nnum_to_show = min(12, len(false_positives))\nif num_to_show > 0:\n    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n    fig.suptitle('False Positives: Predicted as Van Gogh (but are not)', fontsize=16, fontweight='bold')\n    \n    for i, (idx, prob) in enumerate(false_positives[:num_to_show]):\n        row = i // 4\n        col = i % 4\n        \n        # Get image path from test dataset\n        image_path = test_df.iloc[idx]['filepath']\n        image = Image.open(image_path)\n        \n        axes[row, col].imshow(image)\n        axes[row, col].set_title(f'Conf: {prob:.3f}\\n{test_df.iloc[idx][\"artist\"]}', fontsize=10)\n        axes[row, col].axis('off')\n    \n    # Hide empty subplots\n    for i in range(num_to_show, 12):\n        row = i // 4\n        col = i % 4\n        axes[row, col].axis('off')\n    \n    plt.tight_layout()\n    plt.savefig('false_positives.png', dpi=150)\n    plt.show()\n    print(f\"Saved: false_positives.png\")\n    print(f\"\\nTotal False Positives: {len(false_positives)} / {len(all_preds)}\")\nelse:\n    print(\"No False Positives found!\")\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10. Final Summary\n","metadata":{"id":"WeXTrTaHP-Bf"}},{"cell_type":"code","source":"# Final Summary\nprint(\"=\"*60)\nprint(\"PART A - VAN GOGH CLASSIFIER - SUMMARY\")\nprint(\"=\"*60)\n\nprint(\"\\nğŸ“ Dataset:\")\nprint(f\"   Total: {len(df)} | Van Gogh: {df['is_van_gogh'].sum()} | Other: {len(df)-df['is_van_gogh'].sum()}\")\nprint(f\"   Split: 70% train / 15% val / 15% test\")\n\nprint(\"\\nğŸ”§ Best Hyperparameters:\")\nfor k, v in best_params.items():\n    print(f\"   {k}: {v}\")\n\nprint(\"\\nğŸ“Š Performance:\")\nprint(f\"   Best Val Acc:  {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\")\nprint(f\"   Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\nprint(f\"   Test F1-Score: {test_f1:.4f}\")\nprint(f\"   Test AUC-ROC:  {test_auc:.4f}\")\n\nprint(\"\\nğŸ’¾ Saved Files:\")\nprint(\"   best_vangogh_classifier.pth\")\nprint(\"   training_curves.png\")\nprint(\"   confusion_matrix_roc.png\")\n\nprint(\"\\nâœ… Part A Complete!\")\nprint(\"=\"*60)\n","metadata":{"id":"1H9E0j2oP-Bi"},"outputs":[],"execution_count":null}]}
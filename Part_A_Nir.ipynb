{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4202543,"sourceType":"datasetVersion","datasetId":2477766}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom sklearn.model_selection import train_test_split\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.352537Z","iopub.execute_input":"2026-01-02T12:52:12.353186Z","iopub.status.idle":"2026-01-02T12:52:12.357376Z","shell.execute_reply.started":"2026-01-02T12:52:12.353146Z","shell.execute_reply":"2026-01-02T12:52:12.356526Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def is_van_gogh(artist_name: str) -> int:\n    return int(\"van-gogh\" in artist_name.lower())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.358777Z","iopub.execute_input":"2026-01-02T12:52:12.359071Z","iopub.status.idle":"2026-01-02T12:52:12.379663Z","shell.execute_reply.started":"2026-01-02T12:52:12.359036Z","shell.execute_reply":"2026-01-02T12:52:12.378989Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import wandb\n# שים לב לשם הפרמטר key\nwandb.login(key=\"2d0501f02cef1761c98b984600a9770322929664\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.380663Z","iopub.execute_input":"2026-01-02T12:52:12.381016Z","iopub.status.idle":"2026-01-02T12:52:12.568222Z","shell.execute_reply.started":"2026-01-02T12:52:12.380994Z","shell.execute_reply":"2026-01-02T12:52:12.567238Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":51},{"cell_type":"markdown","source":" # ****Data**** ****Preparation**** ","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nbase_dir = \"/kaggle/input/wikiart/Post_Impressionism\"\n\nrecords = []\n\nfor fname in os.listdir(base_dir):\n    if not fname.lower().endswith((\".jpg\", \".png\")):\n        continue\n\n    artist = fname.split(\"_\")[0] #takes the first item of the split- the name of artist\n\n    records.append({\n        \"filepath\": os.path.join(base_dir, fname),\n        \"artist\": artist,\n        \"is_van_gogh\": int(\"van-gogh\" in artist.lower())\n    })\n\ndf = pd.DataFrame(records)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.570379Z","iopub.execute_input":"2026-01-02T12:52:12.570699Z","iopub.status.idle":"2026-01-02T12:52:12.606144Z","shell.execute_reply.started":"2026-01-02T12:52:12.570666Z","shell.execute_reply":"2026-01-02T12:52:12.605146Z"}},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":"##  **check** **the** **dataframe**","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.608017Z","iopub.execute_input":"2026-01-02T12:52:12.608320Z","iopub.status.idle":"2026-01-02T12:52:12.617571Z","shell.execute_reply.started":"2026-01-02T12:52:12.608291Z","shell.execute_reply":"2026-01-02T12:52:12.616779Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"                                            filepath            artist  \\\n0  /kaggle/input/wikiart/Post_Impressionism/paul-...      paul-cezanne   \n1  /kaggle/input/wikiart/Post_Impressionism/suzan...   suzanne-valadon   \n2  /kaggle/input/wikiart/Post_Impressionism/alber...    albert-marquet   \n3  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n4  /kaggle/input/wikiart/Post_Impressionism/paul-...      paul-gauguin   \n\n   is_van_gogh  \n0            0  \n1            0  \n2            0  \n3            1  \n4            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filepath</th>\n      <th>artist</th>\n      <th>is_van_gogh</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/wikiart/Post_Impressionism/paul-...</td>\n      <td>paul-cezanne</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/wikiart/Post_Impressionism/suzan...</td>\n      <td>suzanne-valadon</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/wikiart/Post_Impressionism/alber...</td>\n      <td>albert-marquet</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/wikiart/Post_Impressionism/vince...</td>\n      <td>vincent-van-gogh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/wikiart/Post_Impressionism/paul-...</td>\n      <td>paul-gauguin</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"print (df[\"is_van_gogh\"].value_counts())\nprint (df[df[\"is_van_gogh\"] == 1].head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.618807Z","iopub.execute_input":"2026-01-02T12:52:12.619199Z","iopub.status.idle":"2026-01-02T12:52:12.637913Z","shell.execute_reply.started":"2026-01-02T12:52:12.619165Z","shell.execute_reply":"2026-01-02T12:52:12.637119Z"}},"outputs":[{"name":"stdout","text":"is_van_gogh\n0    5445\n1    1005\nName: count, dtype: int64\n                                             filepath            artist  \\\n3   /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n9   /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n16  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n17  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n18  /kaggle/input/wikiart/Post_Impressionism/vince...  vincent-van-gogh   \n\n    is_van_gogh  \n3             1  \n9             1  \n16            1  \n17            1  \n18            1  \n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"## *splitting the dataframe, and check it*","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Step 1: Initial split - 70% for training and 30% for a temporary set (temp_df)\ntrain_df, temp_df = train_test_split(\n    df,\n    test_size=0.3,           # Reserves 30% of the data for validation and testing\n    stratify=df[\"is_van_gogh\"], # Ensures class proportions are preserved across splits\n    random_state=42          # Sets a seed for reproducibility\n)\n\n# Step 2: Second split - Divide the 30% temporary set equally into validation and test sets\n# This results in 15% of the total data for validation and 15% for testing\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,           # Splits the 30% into two equal 15% parts\n    stratify=temp_df[\"is_van_gogh\"], # Maintains class balance in the remaining subsets\n    random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.638607Z","iopub.execute_input":"2026-01-02T12:52:12.639868Z","iopub.status.idle":"2026-01-02T12:52:12.660722Z","shell.execute_reply.started":"2026-01-02T12:52:12.639832Z","shell.execute_reply":"2026-01-02T12:52:12.660095Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Calculate the total number of rows\ntotal_count = len(df)\n\n# Print percentages of each split relative to the original dataset\nprint(f\"Train set: {len(train_df)} rows ({len(train_df) / total_count:.1%})\")\nprint(f\"Val set:   {len(val_df)} rows ({len(val_df) / total_count:.1%})\")\nprint(f\"Test set:  {len(test_df)} rows ({len(test_df) / total_count:.1%})\")\n\nprint(\"-\" * 30)\n\n# Print class distribution (counts) to verify stratification\nprint(\"Class distribution per split:\")\nprint(\"\\nTrain:\\n\", train_df[\"is_van_gogh\"].value_counts(normalize=True)) # normalize=True gives ratios\nprint(\"\\nVal:\\n\",   val_df[\"is_van_gogh\"].value_counts(normalize=True))\nprint(\"\\nTest:\\n\",  test_df[\"is_van_gogh\"].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.661751Z","iopub.execute_input":"2026-01-02T12:52:12.662292Z","iopub.status.idle":"2026-01-02T12:52:12.671032Z","shell.execute_reply.started":"2026-01-02T12:52:12.662268Z","shell.execute_reply":"2026-01-02T12:52:12.670366Z"}},"outputs":[{"name":"stdout","text":"Train set: 4515 rows (70.0%)\nVal set:   967 rows (15.0%)\nTest set:  968 rows (15.0%)\n------------------------------\nClass distribution per split:\n\nTrain:\n is_van_gogh\n0    0.844075\n1    0.155925\nName: proportion, dtype: float64\n\nVal:\n is_van_gogh\n0    0.844881\n1    0.155119\nName: proportion, dtype: float64\n\nTest:\n is_van_gogh\n0    0.844008\n1    0.155992\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"### Trasfomation class for VGG & AlexNet standard","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\"\"\"\n1 Standard transformations for models pre-trained on ImageNet ( VGG, AlexNet)\n2 Resizes the image to 224x224, the standard input size for VGG and AlexNet\n3 Converts the image to a PyTorch tensor and scales pixels to the [0, 1] range\n4 Normalizes the tensor using ImageNet's mean and standard deviation.\n5 Essential for maintaining consistency with VGG and AlexNet pre-trained weights.\n\n\naugmentaion used: \n- RandomResizedCrop: Crops a random portion of the image and resizes it to 224x224. \n  This helps the model become invariant to scale and object position.\n- RandomHorizontalFlip: Flips the image horizontally with a 50% probability. \n  Useful for art since composition can be mirrored without losing stylistic meaning.\n- RandomRotation: Rotates the image by up to 10 degrees to handle slight tilts.\n- ColorJitter: Randomly changes brightness, contrast, saturation, and hue. \n  This is crucial for Van Gogh's work as it makes the model robust to different lighting \n  conditions and minor color shifts in art photography.\n- ToTensor & Normalize: Standard ImageNet preprocessing for model compatibility.\n\"\"\"\n# will be used to trasform the images to normalized tensor object  --> base_transform(un-normalized picture) and the Augmentaions\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(\n        brightness=0.2,\n        contrast=0.2,\n        saturation=0.2,\n        hue=0.05\n    ),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.671997Z","iopub.execute_input":"2026-01-02T12:52:12.672460Z","iopub.status.idle":"2026-01-02T12:52:12.686444Z","shell.execute_reply.started":"2026-01-02T12:52:12.672439Z","shell.execute_reply":"2026-01-02T12:52:12.685863Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"# Like the Train transforom but without the augmentaions\n\neval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.688545Z","iopub.execute_input":"2026-01-02T12:52:12.688847Z","iopub.status.idle":"2026-01-02T12:52:12.705038Z","shell.execute_reply.started":"2026-01-02T12:52:12.688825Z","shell.execute_reply":"2026-01-02T12:52:12.704369Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"### Making Dataset Object","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom PIL import Image\n\nclass VanGoghDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)   \n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n\n        image = Image.open(row[\"filepath\"]).convert(\"RGB\")\n        label = row[\"is_van_gogh\"]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.705945Z","iopub.execute_input":"2026-01-02T12:52:12.706557Z","iopub.status.idle":"2026-01-02T12:52:12.720382Z","shell.execute_reply.started":"2026-01-02T12:52:12.706534Z","shell.execute_reply":"2026-01-02T12:52:12.719739Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"train_dataset = VanGoghDataset(train_df, transform=train_transform)\nval_dataset   = VanGoghDataset(val_df,   transform=eval_transform)\ntest_dataset  = VanGoghDataset(test_df,  transform=eval_transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.721303Z","iopub.execute_input":"2026-01-02T12:52:12.721884Z","iopub.status.idle":"2026-01-02T12:52:12.737691Z","shell.execute_reply.started":"2026-01-02T12:52:12.721862Z","shell.execute_reply":"2026-01-02T12:52:12.737048Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"train_dataset[0][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.738538Z","iopub.execute_input":"2026-01-02T12:52:12.738826Z","iopub.status.idle":"2026-01-02T12:52:12.805375Z","shell.execute_reply.started":"2026-01-02T12:52:12.738785Z","shell.execute_reply":"2026-01-02T12:52:12.804648Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"tensor([[[-2.1179, -2.1179, -2.1179,  ...,  0.7933,  0.7933, -2.1179],\n         [ 0.4166,  0.5022,  0.6734,  ...,  0.7933,  0.8104, -2.1179],\n         [ 0.5707,  0.6734,  0.7591,  ...,  0.7933,  0.8104, -2.1179],\n         ...,\n         [-2.1179, -0.8849, -1.1075,  ..., -0.6281, -0.4739, -0.3883],\n         [-2.1179, -0.7308, -1.0219,  ..., -0.6794, -0.6109, -0.6109],\n         [-2.1179, -0.9705, -1.0219,  ..., -2.1179, -2.1179, -2.1179]],\n\n        [[-2.0357, -2.0357, -2.0357,  ...,  0.8529,  0.8354, -2.0357],\n         [ 0.2927,  0.2227,  0.4328,  ...,  0.8880,  0.8704, -2.0357],\n         [ 0.3803,  0.4328,  0.6078,  ...,  0.9930,  0.9405, -2.0357],\n         ...,\n         [-2.0357, -0.8627, -1.0378,  ..., -0.4776, -0.2150, -0.1275],\n         [-2.0357, -0.7402, -1.0028,  ..., -0.3901, -0.2850, -0.3375],\n         [-2.0357, -1.0203, -1.0378,  ..., -2.0357, -2.0357, -2.0357]],\n\n        [[-1.8044, -1.8044, -1.8044,  ...,  0.3916,  0.3742, -1.8044],\n         [-0.2881, -0.3578, -0.0092,  ...,  0.4962,  0.4439, -1.8044],\n         [-0.2358, -0.1487,  0.1128,  ...,  0.5659,  0.5136, -1.8044],\n         ...,\n         [-1.8044, -0.7238, -0.8458,  ..., -1.2816, -1.0898, -1.0724],\n         [-1.8044, -0.5495, -0.7761,  ..., -1.2293, -1.0550, -1.1247],\n         [-1.8044, -0.9156, -0.8981,  ..., -1.8044, -1.8044, -1.8044]]])"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"import torch\n# sanity check\n# Retrieve images only (index 0 of the returned tuple)\nimg1 = test_dataset[0][0]\nimg2 = test_dataset.__getitem__(0)[0]\nprint(torch.equal(img1, img2)) \n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.806301Z","iopub.execute_input":"2026-01-02T12:52:12.806549Z","iopub.status.idle":"2026-01-02T12:52:12.863143Z","shell.execute_reply.started":"2026-01-02T12:52:12.806517Z","shell.execute_reply":"2026-01-02T12:52:12.862420Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"### Making  DataLoader obj to later use in our model","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\n# DataLoader for the training set\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=32,      # Number of images per training step\n    shuffle=True,       # Shuffle the data to prevent the model from learning the order\n    num_workers=2       # Use 2 parallel CPU processes to load data faster\n)\n\n# DataLoader for the validation set\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=32,      # Typically matches the training batch size\n    shuffle=False,      # No need to shuffle during evaluation\n    num_workers=2\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.864050Z","iopub.execute_input":"2026-01-02T12:52:12.864280Z","iopub.status.idle":"2026-01-02T12:52:12.868626Z","shell.execute_reply.started":"2026-01-02T12:52:12.864258Z","shell.execute_reply":"2026-01-02T12:52:12.867996Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"# Model Training & Tuning\n","metadata":{}},{"cell_type":"code","source":"import torch\n\n# הגדרת המכשיר - אם יש GPU ב-Kaggle, הוא ישתמש בו\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Working on: {device}\") # ב-Kaggle זה צריך להדפיס cuda\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.869543Z","iopub.execute_input":"2026-01-02T12:52:12.869859Z","iopub.status.idle":"2026-01-02T12:52:12.882202Z","shell.execute_reply.started":"2026-01-02T12:52:12.869837Z","shell.execute_reply":"2026-01-02T12:52:12.881636Z"}},"outputs":[{"name":"stdout","text":"Working on: cuda\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"from torchvision import models\nfrom torch import nn\n\nmodel = models.vgg19(pretrained=True)\n\nmodel.classifier[-1] = nn.Linear(\n    model.classifier[-1].in_features, 2\n)\n\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:12.882974Z","iopub.execute_input":"2026-01-02T12:52:12.883208Z","iopub.status.idle":"2026-01-02T12:52:14.488004Z","shell.execute_reply.started":"2026-01-02T12:52:12.883189Z","shell.execute_reply":"2026-01-02T12:52:14.487391Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# Print only the last layer of the classifier\nprint(model.classifier[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:14.488863Z","iopub.execute_input":"2026-01-02T12:52:14.489131Z","iopub.status.idle":"2026-01-02T12:52:14.493081Z","shell.execute_reply.started":"2026-01-02T12:52:14.489103Z","shell.execute_reply":"2026-01-02T12:52:14.492349Z"}},"outputs":[{"name":"stdout","text":"Linear(in_features=4096, out_features=2, bias=True)\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:14.494040Z","iopub.execute_input":"2026-01-02T12:52:14.494691Z","iopub.status.idle":"2026-01-02T12:52:14.510876Z","shell.execute_reply.started":"2026-01-02T12:52:14.494655Z","shell.execute_reply":"2026-01-02T12:52:14.510151Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"def train_one_epoch(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n\n    for images, labels in loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad()    # each grad will start with grad = zero\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        \n        # בדיקה אם יש ריצה פעילה ב-W&B כדי למנוע את השגיאה שקיבלת\n        if wandb.run is not None:\n            wandb.log({\"batch_loss\": loss.item()})\n\n    return total_loss / len(loader)\n\n@torch.no_grad()\ndef eval_one_epoch(model, loader, criterion):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n\n    for images, labels in loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        total_loss += loss.item()\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n        if wandb.run is not None:\n            wandb.log({\"val_batch_loss\": loss.item()})\n            \n    return total_loss / len(loader), correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:14.511860Z","iopub.execute_input":"2026-01-02T12:52:14.512169Z","iopub.status.idle":"2026-01-02T12:52:14.525976Z","shell.execute_reply.started":"2026-01-02T12:52:14.512138Z","shell.execute_reply":"2026-01-02T12:52:14.525240Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"run = wandb.init(\n    project=\"VanGogh_Classifier\", \n    name=\"Initial_Test\",\n    config={\n        \"architecture\": \"VGG19\",\n        \"epochs\": 3\n    }\n)\n\n\nfor epoch in range(num_epochs):\n    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n    val_loss, val_acc = eval_one_epoch(model, val_loader, criterion)\n    # ...\n\nrun.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:52:14.526907Z","iopub.execute_input":"2026-01-02T12:52:14.527176Z","iopub.status.idle":"2026-01-02T12:58:32.215366Z","shell.execute_reply.started":"2026-01-02T12:52:14.527144Z","shell.execute_reply":"2026-01-02T12:58:32.214506Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260102_125214-3fms02io</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io' target=\"_blank\">Initial_Test</a></strong> to <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▆█▃▄▄▂▅▅▃▄▄▃▃▅▅▂▄▃▁▁▄▅▄▃▂▄▃▂▃▂▃▆▂▁▂▃▂▂▂▅</td></tr><tr><td>val_batch_loss</td><td>▅▆▅▇▅▇▆▃▆█▆▇█▄▅▆▆▂▅█▁▁▃▃▂▅▂▁▆▃▄▂▃▃▆▄▂▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.04852</td></tr><tr><td>val_batch_loss</td><td>0.08983</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">Initial_Test</strong> at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/3fms02io</a><br> View project at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260102_125214-3fms02io/logs</code>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"import optuna\nimport wandb\nfrom torch.utils.data import DataLoader\n\ndef objective(trial):\n    # 1. בחירת היפר-פרמטרים על ידי Optuna\n    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n    \n    # הגדרת ה-DataLoaders בתוך הפונקציה כדי להשתמש ב-batch_size שנבחר\n    curr_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2) # shuffe is important between each epoch\n    curr_val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n    \n    # 2. אתחול ריצה ב-Weights & Biases (חובה לפי ההנחיות)\n    run = wandb.init(\n        project=\"VanGogh_Classifier\",\n        name=f\"trial_{trial.number}\",\n        config={\n            \"lr\": lr, \n            \"optimizer\": optimizer_name, \n            \"batch_size\": batch_size,\n            \"model\": \"VGG19\"\n        },\n        reinit=True\n    )\n\n    # 3. בניית המודל - בכל פעם מחדש עבור הניסיון הנוכחי\n    model = models.vgg19(pretrained=True)\n    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 2)\n    model = model.to(device)\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n    \n    # 4. לולאת אימון לפי מספר Epochs מוגדר\n    num_epochs = 5 \n    for epoch in range(num_epochs):\n        # אימון והערכה בעזרת הפונקציות שכתבת\n        train_loss = train_one_epoch(model, curr_train_loader, optimizer, criterion)\n        val_loss, val_acc = eval_one_epoch(model, curr_val_loader, criterion)\n        \n        # דיווח מדדים ל-W&B בסוף כל Epoch\n        wandb.log({\n            \"epoch\": epoch, \n            \"train_loss\": train_loss, \n            \"val_loss\": val_loss,\n            \"val_acc\": val_acc\n        })\n        \n        # דיווח ל-Optuna ובדיקת \"גיזום\" (Pruning) לחיסכון בזמן\n        trial.report(val_acc, epoch)\n        if trial.should_prune():\n            run.finish()\n            raise optuna.exceptions.TrialPruned()\n\n    # סגירת הריצה ב-W&B והחזרת התוצאה ל-Optuna\n    run.finish()\n    return val_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:02:29.197534Z","iopub.execute_input":"2026-01-02T13:02:29.198303Z","iopub.status.idle":"2026-01-02T13:02:29.205709Z","shell.execute_reply.started":"2026-01-02T13:02:29.198275Z","shell.execute_reply":"2026-01-02T13:02:29.204962Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"# יצירת המחקר\nstudy = optuna.create_study(direction=\"maximize\")\n\n# הרצה לבדיקה ראשונית - 5 דקות בלבד (300 שניות)\nstudy.optimize(objective, timeout=300) \n\nprint(\"--- הבדיקה הסתיימה בהצלחה! ---\")\nprint(\"הפרמטרים הטובים ביותר שמצאנו ב-5 דקות:\", study.best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T13:02:35.525616Z","iopub.execute_input":"2026-01-02T13:02:35.526262Z","iopub.status.idle":"2026-01-02T13:12:01.666945Z","shell.execute_reply.started":"2026-01-02T13:02:35.526236Z","shell.execute_reply":"2026-01-02T13:12:01.666240Z"}},"outputs":[{"name":"stderr","text":"\u001b[32m[I 2026-01-02 13:02:35,527]\u001b[0m A new study created in memory with name: no-name-b63628b2-ab88-4585-83ca-7418a14a4700\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.22.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20260102_130235-8jpgwyyo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo</a>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>▅▄▁▂▂▄▂▆▄▃▂▁▅▃▄▃▂▂▃▃▄▃▂▃▂▂▁█▄▆▂▂▁▁▂▃▁▁▂▃</td></tr><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr><tr><td>val_acc</td><td>▁█▇██</td></tr><tr><td>val_batch_loss</td><td>▅▇▆▇▅▅▇█▂▅▃▃▃▅▂▂▁▁▄▂▁█▁▂▁▃▁▄▄▁▁▂▁▅▂▃▃▃▂▂</td></tr><tr><td>val_loss</td><td>█▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_loss</td><td>0.0237</td></tr><tr><td>epoch</td><td>4</td></tr><tr><td>train_loss</td><td>0.14442</td></tr><tr><td>val_acc</td><td>0.94002</td></tr><tr><td>val_batch_loss</td><td>0.03188</td></tr><tr><td>val_loss</td><td>0.14641</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier/runs/8jpgwyyo</a><br> View project at: <a href='https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier' target=\"_blank\">https://wandb.ai/nirzo555-tel-aviv-university/VanGogh_Classifier</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20260102_130235-8jpgwyyo/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[32m[I 2026-01-02 13:12:01,662]\u001b[0m Trial 0 finished with value: 0.9400206825232679 and parameters: {'lr': 0.0012011055202177864, 'optimizer': 'SGD', 'batch_size': 16}. Best is trial 0 with value: 0.9400206825232679.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"--- הבדיקה הסתיימה בהצלחה! ---\nהפרמטרים הטובים ביותר שמצאנו ב-5 דקות: {'lr': 0.0012011055202177864, 'optimizer': 'SGD', 'batch_size': 16}\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n############# FOR LATER USE ###################\n\ndef imshow(tensor):\n    \"\"\"\n    Converts a normalized PyTorch tensor back to a visual image and displays it.\n    \n    The function reverses the ImageNet normalization by multiplying by the \n    standard deviation and adding the mean. It also clips values to the \n    [0, 1] range to ensure compatibility with matplotlib.\n    \n    Args:\n        tensor (torch.Tensor): A normalized image tensor of shape (C, H, W).\n    \"\"\"\n    img = tensor.numpy().transpose((1, 2, 0))\n    \n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    \n    img = std * img + mean\n    img = np.clip(img, 0, 1)\n    \n    plt.imshow(img)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T12:58:32.226691Z","iopub.status.idle":"2026-01-02T12:58:32.227249Z","shell.execute_reply.started":"2026-01-02T12:58:32.227067Z","shell.execute_reply":"2026-01-02T12:58:32.227095Z"}},"outputs":[],"execution_count":null}]}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part B - Neural Style Transfer: Recreating Van Gogh's Style\n",
        "\n",
        "## Deep Learning Project - Tel Aviv University\n",
        "\n",
        "This notebook implements:\n",
        "- **Part 2A**: Style transfer function (from Nir_part_B)\n",
        "- **Part 2B**: Hyperparameter search using Optuna to find optimal style transfer parameters\n",
        "- **Part 2C**: Application to 20 images using both VGG-19 and AlexNet, with evaluation\n",
        "\n",
        "### Overview:\n",
        "1. **Setup**: Load Part A classifiers and prepare style transfer components\n",
        "2. **Part 2A**: Style transfer function implementation\n",
        "3. **Part 2B**: Optuna search for optimal hyperparameters (content_weight, style_weight, etc.)\n",
        "4. **Part 2C**: Apply style transfer to 20 images, evaluate with both classifiers\n",
        "\n",
        "### Requirements:\n",
        "- Part A trained models (best_vangogh_classifier.pth)\n",
        "- Van Gogh paintings as style images\n",
        "- Content images (personal photos or other images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running on Kaggle\n",
        "import os\n",
        "import sys\n",
        "\n",
        "IN_KAGGLE = os.path.exists('/kaggle')\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_KAGGLE:\n",
        "    print(\"Running on Kaggle\")\n",
        "elif IN_COLAB:\n",
        "    print(\"Running on Google Colab\")\n",
        "else:\n",
        "    print(\"Running locally\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q optuna wandb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# Hyperparameter tuning\n",
        "import optuna\n",
        "import wandb\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# Setup device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Part A Classifiers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load or Create Part A trained models\n",
        "# These will serve as \"judges\" to evaluate style transfer quality\n",
        "\n",
        "import os  # Ensure os is imported for path operations\n",
        "\n",
        "# Model creation function from Part A\n",
        "def create_model(model_name='VGG19', freeze_features=True, dropout=0.5):\n",
        "    \"\"\"\n",
        "    Create model with binary classifier (from Part A).\n",
        "    Implements Smart Fine-tuning: When freeze_features=False, unfreezes only top layers.\n",
        "    \n",
        "    Args:\n",
        "        model_name: 'VGG19' or 'AlexNet'\n",
        "        freeze_features: If True, freeze feature extractor (only train classifier)\n",
        "                        If False, unfreeze only top layers (Smart Fine-tuning)\n",
        "        dropout: Dropout rate for classifier (0.0 to 0.7)\n",
        "    \"\"\"\n",
        "    if model_name == 'VGG19':\n",
        "        model = models.vgg19(weights='IMAGENET1K_V1')\n",
        "        # First, freeze all feature layers by default\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # Smart Fine-tuning: If freeze_features=False, unfreeze only the last 8 layers\n",
        "        if not freeze_features:\n",
        "            # VGG19 features has 36 layers (0-35), unfreeze last 8 layers (28-35)\n",
        "            for i in range(28, 36):\n",
        "                for param in model.features[i].parameters():\n",
        "                    param.requires_grad = True\n",
        "        \n",
        "        # Modify classifier: VGG19 classifier[6] is the last Linear layer\n",
        "        num_features = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(num_features, 2)  # Binary classification\n",
        "        )\n",
        "    elif model_name == 'AlexNet':\n",
        "        model = models.alexnet(weights='IMAGENET1K_V1')\n",
        "        # First, freeze all feature layers by default\n",
        "        for param in model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "        \n",
        "        # Smart Fine-tuning: If freeze_features=False, unfreeze only the last 2 layers\n",
        "        if not freeze_features:\n",
        "            # AlexNet features has 12 layers (0-11), unfreeze last 2 layers (10-11)\n",
        "            for i in range(10, 12):\n",
        "                for param in model.features[i].parameters():\n",
        "                    param.requires_grad = True\n",
        "        \n",
        "        # Modify classifier: AlexNet classifier[6] is the last Linear layer\n",
        "        num_features = model.classifier[6].in_features\n",
        "        model.classifier[6] = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(num_features, 2)  # Binary classification\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model type: {model_name}\")\n",
        "    \n",
        "    return model.to(device)\n",
        "\n",
        "def load_classifier(model_name='VGG19', checkpoint_path=None):\n",
        "    \"\"\"Try to load a trained classifier from Part A, or create a new one\"\"\"\n",
        "    if checkpoint_path is None:\n",
        "        # Try to find checkpoint file\n",
        "        possible_paths = [\n",
        "            '/kaggle/working/best_vangogh_classifier.pth',\n",
        "            '/kaggle/input/part-a-models/best_vangogh_classifier.pth',\n",
        "            'best_vangogh_classifier.pth'\n",
        "        ]\n",
        "        checkpoint_path = None\n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                checkpoint_path = path\n",
        "                break\n",
        "    \n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        # Load from checkpoint\n",
        "        print(f\"Loading classifier from: {checkpoint_path}\")\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "        best_params = checkpoint.get('best_params', {})\n",
        "        \n",
        "        # Create model based on saved parameters\n",
        "        model_type = best_params.get('model_name', model_name)\n",
        "        dropout = best_params.get('dropout', 0.5)\n",
        "        freeze_features = best_params.get('freeze_features', True)\n",
        "        \n",
        "        model = create_model(model_name=model_type, freeze_features=freeze_features, dropout=dropout)\n",
        "        \n",
        "        # Load weights\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.eval()\n",
        "        \n",
        "        print(f\"Loaded {model_type} classifier (Val Acc: {checkpoint.get('best_val_acc', 'N/A'):.4f})\")\n",
        "        return model, model_type\n",
        "    else:\n",
        "        # No checkpoint found - create a new model with default parameters\n",
        "        print(f\"No checkpoint found. Creating new {model_name} classifier with default parameters.\")\n",
        "        print(\"Note: This model will not be trained. For best results, train Part A first.\")\n",
        "        \n",
        "        # Use reasonable default parameters (similar to Part A best params)\n",
        "        if model_name == 'VGG19':\n",
        "            model = create_model(model_name='VGG19', freeze_features=False, dropout=0.4)\n",
        "        else:\n",
        "            model = create_model(model_name='AlexNet', freeze_features=False, dropout=0.4)\n",
        "        \n",
        "        model.eval()\n",
        "        print(f\"Created {model_name} classifier (untrained - will use ImageNet features only)\")\n",
        "        return model, model_name\n",
        "\n",
        "# Load the judge model (try to load from checkpoint, or create new)\n",
        "# We'll use this as the judge for hyperparameter search\n",
        "try:\n",
        "    judge_model, judge_model_name = load_classifier()\n",
        "    print(f\"\\nUsing {judge_model_name} as judge for hyperparameter search\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Creating default VGG19 classifier as fallback...\")\n",
        "    judge_model, judge_model_name = load_classifier('VGG19')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Part 2A: Style Transfer Function\n",
        "\n",
        "This section implements the generic style transfer function (from Nir_part_B)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Image loading and preprocessing\n",
        "imsize = 512 if torch.cuda.is_available() else 128\n",
        "\n",
        "loader = transforms.Compose([\n",
        "    transforms.Resize((imsize, imsize)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def image_loader(image_path):\n",
        "    \"\"\"Load and preprocess an image\"\"\"\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = loader(image).unsqueeze(0)\n",
        "    return image.to(device, torch.float)\n",
        "\n",
        "def imshow(tensor, title=None, save_path=None):\n",
        "    \"\"\"Display a tensor as an image\"\"\"\n",
        "    image = tensor.cpu().clone().detach().squeeze(0)\n",
        "    inv_normalize = transforms.Normalize(\n",
        "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "        std=[1/0.229, 1/0.224, 1/0.225]\n",
        "    )\n",
        "    image = inv_normalize(image)\n",
        "    image = transforms.ToPILImage()(image.clamp(0, 1))\n",
        "    \n",
        "    plt.imshow(image)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    if save_path:\n",
        "        image.save(save_path)\n",
        "    \n",
        "    plt.show()\n",
        "    return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function for Gram matrix (used in style loss)\n",
        "def get_gram_matrix(tensor):\n",
        "    \"\"\"Compute Gram matrix for style loss\"\"\"\n",
        "    b, c, h, w = tensor.size()\n",
        "    features = tensor.view(b * c, h * w)\n",
        "    gram = torch.mm(features, features.t())\n",
        "    return gram / (b * c * h * w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to extract features from model layers\n",
        "def get_features(image, model, layers_dict):\n",
        "    \"\"\"Extract activation maps from selected layers in the model\"\"\"\n",
        "    features = {}\n",
        "    x = image\n",
        "    for name, layer in model._modules.items():\n",
        "        x = layer(x)\n",
        "        if name in layers_dict:\n",
        "            features[layers_dict[name]] = x\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def neural_style_transfer(model, content_image, style_image, \n",
        "                          content_layers, style_layers, \n",
        "                          content_weight, style_weight, \n",
        "                          style_layer_weights, num_steps=300):\n",
        "    \"\"\"\n",
        "    Generic neural style transfer function\n",
        "    \n",
        "    Args:\n",
        "        model: Pre-trained network (VGG-19 or AlexNet features)\n",
        "        content_image: Image whose structure to preserve\n",
        "        style_image: Image whose artistic style to apply\n",
        "        content_layers: Dict mapping layer indices to names for content features\n",
        "        style_layers: Dict mapping layer indices to names for style features\n",
        "        content_weight: Scalar (α) to control emphasis on content\n",
        "        style_weight: Scalar (β) to control intensity of style\n",
        "        style_layer_weights: Dict of weights to balance each style layer contribution\n",
        "        num_steps: Number of optimization steps\n",
        "    \n",
        "    Returns:\n",
        "        Final stylized image tensor\n",
        "    \"\"\"\n",
        "    # Set model to eval mode and freeze parameters\n",
        "    model.eval()\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    # Initialize target image as clone of content image\n",
        "    target = content_image.clone().requires_grad_(True)\n",
        "    \n",
        "    # Combine all layers needed\n",
        "    all_layers = {**content_layers, **style_layers}\n",
        "    \n",
        "    # Extract fixed features from source images\n",
        "    content_features = get_features(content_image, model, content_layers)\n",
        "    style_features = get_features(style_image, model, style_layers)\n",
        "    \n",
        "    # Compute Gram matrices for style image\n",
        "    style_grams = {layer: get_gram_matrix(style_features[layer]) for layer in style_features}\n",
        "\n",
        "    # Setup optimizer (LBFGS recommended for NST)\n",
        "    optimizer = optim.LBFGS([target])\n",
        "    \n",
        "    # Optimization loop\n",
        "    for i in range(num_steps):\n",
        "        def closure():\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Extract current features from target\n",
        "            target_features = get_features(target, model, all_layers)\n",
        "            \n",
        "            # Compute Content Loss\n",
        "            c_loss = 0\n",
        "            for layer in content_layers.values():\n",
        "                c_loss += torch.mean((target_features[layer] - content_features[layer])**2)\n",
        "            \n",
        "            # Compute Style Loss\n",
        "            s_loss = 0\n",
        "            for layer in style_layers.values():\n",
        "                target_gram = get_gram_matrix(target_features[layer])\n",
        "                style_gram = style_grams[layer]\n",
        "                layer_weight = style_layer_weights.get(layer, 1.0)\n",
        "                s_loss += layer_weight * torch.mean((target_gram - style_gram)**2)\n",
        "            \n",
        "            # Total weighted loss\n",
        "            total_loss = content_weight * c_loss + style_weight * s_loss\n",
        "            total_loss.backward()\n",
        "            \n",
        "            return total_loss\n",
        "\n",
        "        optimizer.step(closure)\n",
        "        \n",
        "        # Optional: print progress every 50 steps\n",
        "        if (i + 1) % 50 == 0:\n",
        "            print(f\"Step {i+1}/{num_steps} completed\")\n",
        "    \n",
        "    return target.detach()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prepare Style and Content Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find Van Gogh paintings to use as style images\n",
        "# We need at least 5 different Van Gogh paintings\n",
        "\n",
        "def find_van_gogh_paintings(base_dir, min_count=5):\n",
        "    \"\"\"Find Van Gogh painting files\"\"\"\n",
        "    van_gogh_files = []\n",
        "    \n",
        "    # Search for specific famous paintings\n",
        "    keywords = [\n",
        "        \"starry-night\",\n",
        "        \"sunflowers\",\n",
        "        \"crows\",  # Wheatfield with Crows\n",
        "        \"cafe-terrace\",\n",
        "        \"irises\",\n",
        "        \"bedroom\",\n",
        "        \"almond-blossom\",\n",
        "        \"self-portrait\"\n",
        "    ]\n",
        "    \n",
        "    for fname in os.listdir(base_dir):\n",
        "        if not fname.lower().endswith((\".jpg\", \".png\")):\n",
        "            continue\n",
        "        \n",
        "        if \"van-gogh\" in fname.lower():\n",
        "            # Check if it matches any keyword\n",
        "            for keyword in keywords:\n",
        "                if keyword in fname.lower():\n",
        "                    filepath = os.path.join(base_dir, fname)\n",
        "                    if filepath not in van_gogh_files:\n",
        "                        van_gogh_files.append(filepath)\n",
        "                    break\n",
        "    \n",
        "    # If we don't have enough, add more random Van Gogh paintings\n",
        "    if len(van_gogh_files) < min_count:\n",
        "        for fname in os.listdir(base_dir):\n",
        "            if len(van_gogh_files) >= min_count:\n",
        "                break\n",
        "            if not fname.lower().endswith((\".jpg\", \".png\")):\n",
        "                continue\n",
        "            if \"van-gogh\" in fname.lower():\n",
        "                filepath = os.path.join(base_dir, fname)\n",
        "                if filepath not in van_gogh_files:\n",
        "                    van_gogh_files.append(filepath)\n",
        "    \n",
        "    return van_gogh_files[:min_count] if len(van_gogh_files) >= min_count else van_gogh_files\n",
        "\n",
        "# Find base directory\n",
        "possible_dirs = [\n",
        "    \"/kaggle/input/wikiart/Post_Impressionism\",\n",
        "    \"/kaggle/input/Post_Impressionism\",\n",
        "    \"/content/data/Post_Impressionism\",\n",
        "    \"./Post_Impressionism\"\n",
        "]\n",
        "\n",
        "base_dir = None\n",
        "for dir_path in possible_dirs:\n",
        "    if os.path.exists(dir_path):\n",
        "        base_dir = dir_path\n",
        "        break\n",
        "\n",
        "if base_dir:\n",
        "    style_image_paths = find_van_gogh_paintings(base_dir, min_count=5)\n",
        "    print(f\"Found {len(style_image_paths)} Van Gogh style images:\")\n",
        "    for i, path in enumerate(style_image_paths, 1):\n",
        "        print(f\"  {i}. {os.path.basename(path)}\")\n",
        "else:\n",
        "    print(\"Warning: Could not find Post_Impressionism directory\")\n",
        "    print(\"Please manually specify style_image_paths below\")\n",
        "    style_image_paths = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Manually specify style images if automatic search didn't work\n",
        "# Or add your preferred Van Gogh paintings here\n",
        "if len(style_image_paths) < 5:\n",
        "    # Example paths (adjust based on your setup)\n",
        "    style_image_paths = [\n",
        "        \"/kaggle/input/wikiart/Post_Impressionism/vincent-van-gogh_the-starry-night-1889(1).jpg\",\n",
        "        \"/kaggle/input/wikiart/Post_Impressionism/vincent-van-gogh_sunflowers-1888.jpg\",\n",
        "        \"/kaggle/input/wikiart/Post_Impressionism/vincent-van-gogh_wheatfield-with-crows-1890.jpg\",\n",
        "        \"/kaggle/input/wikiart/Post_Impressionism/vincent-van-gogh_cafe-terrace-at-night-1888.jpg\",\n",
        "        \"/kaggle/input/wikiart/Post_Impressionism/vincent-van-gogh_irises-1889.jpg\"\n",
        "    ]\n",
        "    \n",
        "    # Filter to only existing files\n",
        "    style_image_paths = [p for p in style_image_paths if os.path.exists(p)]\n",
        "    print(f\"Using {len(style_image_paths)} manually specified style images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare content images\n",
        "# You should provide 20 content images (personal photos are encouraged!)\n",
        "# For now, we'll create a placeholder that you can replace\n",
        "\n",
        "def find_content_images(content_dir=None, count=20):\n",
        "    \"\"\"Find content images for style transfer\"\"\"\n",
        "    content_paths = []\n",
        "    \n",
        "    # Try to find content images directory\n",
        "    possible_dirs = [\n",
        "        \"/kaggle/input/content\",\n",
        "        \"/kaggle/input/content-images\",\n",
        "        \"./content_images\",\n",
        "        content_dir\n",
        "    ]\n",
        "    \n",
        "    content_base = None\n",
        "    for dir_path in possible_dirs:\n",
        "        if dir_path and os.path.exists(dir_path):\n",
        "            content_base = dir_path\n",
        "            break\n",
        "    \n",
        "    if content_base:\n",
        "        # Load all images from directory\n",
        "        for fname in os.listdir(content_base):\n",
        "            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
        "                content_paths.append(os.path.join(content_base, fname))\n",
        "                if len(content_paths) >= count:\n",
        "                    break\n",
        "    \n",
        "    return content_paths\n",
        "\n",
        "content_image_paths = find_content_images(count=20)\n",
        "\n",
        "if len(content_image_paths) < 20:\n",
        "    print(f\"Warning: Found only {len(content_image_paths)} content images\")\n",
        "    print(\"Please add more content images or use images from the dataset\")\n",
        "    \n",
        "    # Fallback: use some non-Van-Gogh paintings as content images\n",
        "    if base_dir:\n",
        "        print(\"Using non-Van-Gogh paintings as content images...\")\n",
        "        for fname in os.listdir(base_dir):\n",
        "            if len(content_image_paths) >= 20:\n",
        "                break\n",
        "            if not fname.lower().endswith((\".jpg\", \".png\")):\n",
        "                continue\n",
        "            if \"van-gogh\" not in fname.lower():\n",
        "                content_image_paths.append(os.path.join(base_dir, fname))\n",
        "\n",
        "print(f\"\\nPrepared {len(content_image_paths)} content images\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define Layer Configurations for VGG-19 and AlexNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# VGG-19 layer configuration\n",
        "VGG19_CONTENT_LAYERS = {'21': 'content'}  # conv4_2\n",
        "\n",
        "VGG19_STYLE_LAYERS = {\n",
        "    '0': 'conv1_1',\n",
        "    '5': 'conv2_1',\n",
        "    '10': 'conv3_1',\n",
        "    '19': 'conv4_1',\n",
        "    '28': 'conv5_1'\n",
        "}\n",
        "\n",
        "VGG19_STYLE_LAYER_WEIGHTS = {\n",
        "    'conv1_1': 1.0,\n",
        "    'conv2_1': 0.8,\n",
        "    'conv3_1': 0.5,\n",
        "    'conv4_1': 0.3,\n",
        "    'conv5_1': 0.1\n",
        "}\n",
        "\n",
        "# AlexNet layer configuration (simpler, fewer layers)\n",
        "ALEXNET_CONTENT_LAYERS = {'8': 'content'}  # conv3\n",
        "\n",
        "ALEXNET_STYLE_LAYERS = {\n",
        "    '0': 'conv1',\n",
        "    '3': 'conv2',\n",
        "    '6': 'conv3'\n",
        "}\n",
        "\n",
        "ALEXNET_STYLE_LAYER_WEIGHTS = {\n",
        "    'conv1': 1.0,\n",
        "    'conv2': 0.75,\n",
        "    'conv3': 0.5\n",
        "}\n",
        "\n",
        "print(\"Layer configurations defined for VGG-19 and AlexNet\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Part 2B: Hyperparameter Search with Optuna\n",
        "\n",
        "Find optimal style transfer hyperparameters using the Part 1 classifier as a judge.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Login to Weights & Biases\n",
        "wandb.login(key=\"16d1bc863b28f81253ac0ee253b453393791a7e1\")\n",
        "print(\"Logged in to Weights & Biases\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load VGG-19 features model for style transfer\n",
        "vgg_features = models.vgg19(weights='IMAGENET1K_V1').features.to(device).eval()\n",
        "for param in vgg_features.parameters():\n",
        "    param.requires_grad = False\n",
        "print(\"VGG-19 features model loaded for style transfer\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select fixed content and style images for hyperparameter search\n",
        "# Using one content image and one style image for consistency\n",
        "if len(content_image_paths) > 0 and len(style_image_paths) > 0:\n",
        "    search_content_path = content_image_paths[0]\n",
        "    search_style_path = style_image_paths[0]  # Use first Van Gogh painting\n",
        "    \n",
        "    search_content_img = image_loader(search_content_path)\n",
        "    search_style_img = image_loader(search_style_path)\n",
        "    \n",
        "    print(f\"Using content image: {os.path.basename(search_content_path)}\")\n",
        "    print(f\"Using style image: {os.path.basename(search_style_path)}\")\n",
        "    \n",
        "    # Display the images\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    imshow(search_content_img, \"Content Image\")\n",
        "    plt.subplot(1, 2, 2)\n",
        "    imshow(search_style_img, \"Style Image (Van Gogh)\")\n",
        "else:\n",
        "    raise ValueError(\"Need at least one content and one style image for hyperparameter search!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def style_transfer_objective(trial):\n",
        "    \"\"\"\n",
        "    Optuna objective function for style transfer hyperparameter search.\n",
        "    Maximizes the classifier's probability that the stylized image is Van Gogh.\n",
        "    \"\"\"\n",
        "    # Suggest hyperparameters\n",
        "    content_weight = trial.suggest_float(\"content_weight\", 1e-4, 1e2, log=True)\n",
        "    style_weight = trial.suggest_float(\"style_weight\", 1e3, 1e9, log=True)\n",
        "    \n",
        "    # Optional: also search style_layer_weights (can be commented out for faster search)\n",
        "    # For now, use fixed style_layer_weights to reduce search space\n",
        "    \n",
        "    # Run style transfer with suggested parameters\n",
        "    # Use fewer steps for faster search (can increase for final results)\n",
        "    num_steps = 100  # Reduced for faster hyperparameter search\n",
        "    \n",
        "    try:\n",
        "        stylized_image = neural_style_transfer(\n",
        "            vgg_features,\n",
        "            search_content_img,\n",
        "            search_style_img,\n",
        "            VGG19_CONTENT_LAYERS,\n",
        "            VGG19_STYLE_LAYERS,\n",
        "            content_weight,\n",
        "            style_weight,\n",
        "            VGG19_STYLE_LAYER_WEIGHTS,\n",
        "            num_steps=num_steps\n",
        "        )\n",
        "        \n",
        "        # Prepare image for classifier (resize to 224x224)\n",
        "        judge_input = F.interpolate(stylized_image, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "        \n",
        "        # Get score from judge (classifier)\n",
        "        with torch.no_grad():\n",
        "            output = judge_model(judge_input)\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            # Assuming class 1 is \"Van Gogh\" (check your model's class order)\n",
        "            van_gogh_prob = probabilities[0][1].item()  # Probability of being Van Gogh\n",
        "        \n",
        "        return van_gogh_prob\n",
        "    \n",
        "    except Exception as e:\n",
        "        print(f\"Error in trial {trial.number}: {e}\")\n",
        "        return 0.0  # Return low score on error\n",
        "\n",
        "print(\"Style transfer objective function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Optuna hyperparameter search\n",
        "print(\"=\"*60)\n",
        "print(\"PART 2B: HYPERPARAMETER SEARCH FOR STYLE TRANSFER\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nObjective: Maximize classifier's Van Gogh probability\")\n",
        "print(\"This may take 30-60 minutes depending on number of trials...\")\n",
        "\n",
        "# Create study\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=2)\n",
        ")\n",
        "\n",
        "# Initialize wandb run for tracking\n",
        "wandb_run = wandb.init(\n",
        "    project=\"VanGogh_StyleTransfer_HPO\",\n",
        "    name=\"style_transfer_hyperparameter_search\",\n",
        "    config={\"judge_model\": judge_model_name}\n",
        ")\n",
        "\n",
        "# Track start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Run optimization (adjust n_trials and timeout as needed)\n",
        "# For faster results, use fewer trials; for better results, use more\n",
        "study.optimize(style_transfer_objective, n_trials=15, timeout=3600, show_progress_bar=True)\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "elapsed_minutes = elapsed_time / 60\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"HYPERPARAMETER SEARCH COMPLETE!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTime taken: {elapsed_minutes:.2f} minutes ({elapsed_time:.0f} seconds)\")\n",
        "print(f\"Completed trials: {len(study.trials)}\")\n",
        "print(f\"\\nBest Van Gogh probability: {study.best_value:.4f}\")\n",
        "print(f\"\\nOptimal hyperparameters:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Log best parameters to wandb\n",
        "wandb.log({\"best_van_gogh_prob\": study.best_value, **study.best_params})\n",
        "wandb_run.finish()\n",
        "\n",
        "# Save results\n",
        "best_style_transfer_params = study.best_params\n",
        "with open('best_style_transfer_params.pkl', 'wb') as f:\n",
        "    pickle.dump(best_style_transfer_params, f)\n",
        "print(\"\\nSaved optimal parameters to 'best_style_transfer_params.pkl'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Part 2C: Application & Evaluation\n",
        "\n",
        "Apply style transfer to 20 images using both VGG-19 and AlexNet, then evaluate with both classifiers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load optimal hyperparameters (or use defaults if search wasn't run)\n",
        "if 'best_style_transfer_params' not in globals():\n",
        "    if os.path.exists('best_style_transfer_params.pkl'):\n",
        "        with open('best_style_transfer_params.pkl', 'rb') as f:\n",
        "            best_style_transfer_params = pickle.load(f)\n",
        "        print(f\"Loaded optimal parameters from file\")\n",
        "    else:\n",
        "        # Use reasonable defaults if search wasn't run\n",
        "        best_style_transfer_params = {\n",
        "            'content_weight': 1e-2,\n",
        "            'style_weight': 1e6\n",
        "        }\n",
        "        print(\"Using default parameters (hyperparameter search not run)\")\n",
        "\n",
        "print(f\"\\nUsing hyperparameters:\")\n",
        "for k, v in best_style_transfer_params.items():\n",
        "    print(f\"  {k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load both VGG-19 and AlexNet feature models\n",
        "vgg19_features = models.vgg19(weights='IMAGENET1K_V1').features.to(device).eval()\n",
        "for param in vgg19_features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "alexnet_features = models.alexnet(weights='IMAGENET1K_V1').features.to(device).eval()\n",
        "for param in alexnet_features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"Both VGG-19 and AlexNet feature models loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set consistent number of epochs/steps for all style transfers\n",
        "# This must be the same for all images and models (project requirement)\n",
        "CONSISTENT_NUM_STEPS = 300  # You can adjust this, but keep it consistent\n",
        "\n",
        "print(f\"Using {CONSISTENT_NUM_STEPS} optimization steps for all style transfers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to apply style transfer and evaluate\n",
        "def apply_and_evaluate_style_transfer(content_path, style_path, model_name='VGG19', \n",
        "                                     save_dir='/kaggle/working/stylized_images'):\n",
        "    \"\"\"\n",
        "    Apply style transfer and evaluate with both classifiers\n",
        "    \n",
        "    Returns:\n",
        "        dict with stylized image, evaluation scores, and metadata\n",
        "    \"\"\"\n",
        "    # Load images\n",
        "    content_img = image_loader(content_path)\n",
        "    style_img = image_loader(style_path)\n",
        "    \n",
        "    # Select model and layer configuration\n",
        "    if model_name == 'VGG19':\n",
        "        model = vgg19_features\n",
        "        content_layers = VGG19_CONTENT_LAYERS\n",
        "        style_layers = VGG19_STYLE_LAYERS\n",
        "        style_layer_weights = VGG19_STYLE_LAYER_WEIGHTS\n",
        "    elif model_name == 'AlexNet':\n",
        "        model = alexnet_features\n",
        "        content_layers = ALEXNET_CONTENT_LAYERS\n",
        "        style_layers = ALEXNET_STYLE_LAYERS\n",
        "        style_layer_weights = ALEXNET_STYLE_LAYER_WEIGHTS\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model: {model_name}\")\n",
        "    \n",
        "    # Apply style transfer\n",
        "    print(f\"\\nApplying {model_name} style transfer...\")\n",
        "    stylized = neural_style_transfer(\n",
        "        model, content_img, style_img,\n",
        "        content_layers, style_layers,\n",
        "        best_style_transfer_params['content_weight'],\n",
        "        best_style_transfer_params['style_weight'],\n",
        "        style_layer_weights,\n",
        "        num_steps=CONSISTENT_NUM_STEPS\n",
        "    )\n",
        "    \n",
        "    # Prepare for classifier evaluation\n",
        "    eval_input = F.interpolate(stylized, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "    \n",
        "    # Evaluate with judge model (and potentially other classifiers)\n",
        "    with torch.no_grad():\n",
        "        output = judge_model(eval_input)\n",
        "        probs = F.softmax(output, dim=1)\n",
        "        judge_van_gogh_prob = probs[0][1].item()\n",
        "        judge_prediction = output.argmax(dim=1).item()\n",
        "    \n",
        "    # Save stylized image\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    content_name = os.path.splitext(os.path.basename(content_path))[0]\n",
        "    style_name = os.path.splitext(os.path.basename(style_path))[0]\n",
        "    save_path = os.path.join(save_dir, f\"{model_name}_{content_name}_{style_name}.jpg\")\n",
        "    \n",
        "    # Convert and save\n",
        "    result_image = imshow(stylized, f\"{model_name}: {os.path.basename(content_path)}\", save_path=save_path)\n",
        "    \n",
        "    return {\n",
        "        'stylized_image': stylized,\n",
        "        'content_path': content_path,\n",
        "        'style_path': style_path,\n",
        "        'model_name': model_name,\n",
        "        'judge_van_gogh_prob': judge_van_gogh_prob,\n",
        "        'judge_prediction': judge_prediction,\n",
        "        'save_path': save_path\n",
        "    }\n",
        "\n",
        "print(\"Style transfer application function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply style transfer to 20 images with both VGG-19 and AlexNet\n",
        "# Use at least 5 different Van Gogh paintings as style images\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"PART 2C: APPLYING STYLE TRANSFER TO 20 IMAGES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Ensure we have enough content and style images\n",
        "num_content = min(20, len(content_image_paths))\n",
        "num_styles = min(5, len(style_image_paths))\n",
        "\n",
        "print(f\"\\nProcessing {num_content} content images with {num_styles} style images\")\n",
        "print(f\"Using {CONSISTENT_NUM_STEPS} steps for all transfers\")\n",
        "\n",
        "# Store all results\n",
        "all_results = []\n",
        "\n",
        "# Process each content image with each style image, using both models\n",
        "content_to_process = content_image_paths[:num_content]\n",
        "styles_to_use = style_image_paths[:num_styles]\n",
        "\n",
        "# Distribute style images across content images\n",
        "# Each content image gets styled with different Van Gogh paintings\n",
        "for i, content_path in enumerate(tqdm(content_to_process, desc=\"Processing content images\")):\n",
        "    # Cycle through style images\n",
        "    style_idx = i % num_styles\n",
        "    style_path = styles_to_use[style_idx]\n",
        "    \n",
        "    # Apply with VGG-19\n",
        "    try:\n",
        "        vgg_result = apply_and_evaluate_style_transfer(\n",
        "            content_path, style_path, model_name='VGG19'\n",
        "        )\n",
        "        all_results.append(vgg_result)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with VGG-19 on {content_path}: {e}\")\n",
        "    \n",
        "    # Apply with AlexNet\n",
        "    try:\n",
        "        alexnet_result = apply_and_evaluate_style_transfer(\n",
        "            content_path, style_path, model_name='AlexNet'\n",
        "        )\n",
        "        all_results.append(alexnet_result)\n",
        "    except Exception as e:\n",
        "        print(f\"Error with AlexNet on {content_path}: {e}\")\n",
        "\n",
        "print(f\"\\nCompleted {len(all_results)} style transfers\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate results with both classifiers\n",
        "# Load both VGG-19 and AlexNet classifiers if available\n",
        "\n",
        "def evaluate_with_classifier(stylized_image, classifier, classifier_name):\n",
        "    \"\"\"Evaluate a stylized image with a classifier\"\"\"\n",
        "    eval_input = F.interpolate(stylized_image, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        output = classifier(eval_input)\n",
        "        probs = F.softmax(output, dim=1)\n",
        "        van_gogh_prob = probs[0][1].item()\n",
        "        prediction = output.argmax(dim=1).item()\n",
        "    \n",
        "    return {\n",
        "        f'{classifier_name}_van_gogh_prob': van_gogh_prob,\n",
        "        f'{classifier_name}_prediction': prediction\n",
        "    }\n",
        "\n",
        "# Try to load both classifiers\n",
        "vgg19_classifier = None\n",
        "alexnet_classifier = None\n",
        "\n",
        "try:\n",
        "    # Try loading VGG-19 classifier\n",
        "    vgg19_classifier, _ = load_classifier('VGG19')\n",
        "except:\n",
        "    print(\"Could not load separate VGG-19 classifier, using judge model\")\n",
        "\n",
        "try:\n",
        "    # Try loading AlexNet classifier\n",
        "    alexnet_classifier, _ = load_classifier('AlexNet')\n",
        "except:\n",
        "    print(\"Could not load separate AlexNet classifier, using judge model\")\n",
        "\n",
        "# Evaluate all results with available classifiers\n",
        "print(\"\\nEvaluating all stylized images with classifiers...\")\n",
        "\n",
        "for result in tqdm(all_results, desc=\"Evaluating\"):\n",
        "    stylized = result['stylized_image']\n",
        "    \n",
        "    # Evaluate with judge model (already done, but add to results)\n",
        "    result['judge_eval'] = {\n",
        "        'van_gogh_prob': result['judge_van_gogh_prob'],\n",
        "        'prediction': result['judge_prediction']\n",
        "    }\n",
        "    \n",
        "    # Evaluate with VGG-19 classifier if available\n",
        "    if vgg19_classifier is not None:\n",
        "        vgg_eval = evaluate_with_classifier(stylized, vgg19_classifier, 'VGG19_classifier')\n",
        "        result.update(vgg_eval)\n",
        "    \n",
        "    # Evaluate with AlexNet classifier if available\n",
        "    if alexnet_classifier is not None:\n",
        "        alexnet_eval = evaluate_with_classifier(stylized, alexnet_classifier, 'AlexNet_classifier')\n",
        "        result.update(alexnet_eval)\n",
        "\n",
        "print(\"\\nEvaluation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze and summarize results\n",
        "print(\"=\"*60)\n",
        "print(\"PART 2C: RESULTS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Convert results to DataFrame for analysis\n",
        "results_df = pd.DataFrame([\n",
        "    {\n",
        "        'content': os.path.basename(r['content_path']),\n",
        "        'style': os.path.basename(r['style_path']),\n",
        "        'model': r['model_name'],\n",
        "        'judge_van_gogh_prob': r['judge_van_gogh_prob'],\n",
        "        'judge_prediction': r['judge_prediction']\n",
        "    }\n",
        "    for r in all_results\n",
        "])\n",
        "\n",
        "# Add classifier evaluations if available\n",
        "for r in all_results:\n",
        "    if 'VGG19_classifier_van_gogh_prob' in r:\n",
        "        idx = results_df[results_df['content'] == os.path.basename(r['content_path'])].index[0]\n",
        "        results_df.loc[idx, 'VGG19_classifier_van_gogh_prob'] = r.get('VGG19_classifier_van_gogh_prob', None)\n",
        "    if 'AlexNet_classifier_van_gogh_prob' in r:\n",
        "        idx = results_df[results_df['content'] == os.path.basename(r['content_path'])].index[0]\n",
        "        results_df.loc[idx, 'AlexNet_classifier_van_gogh_prob'] = r.get('AlexNet_classifier_van_gogh_prob', None)\n",
        "\n",
        "print(\"\\nResults Summary:\")\n",
        "print(results_df.head(10))\n",
        "\n",
        "# Statistics by model\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STATISTICS BY STYLE TRANSFER MODEL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for model in ['VGG19', 'AlexNet']:\n",
        "    model_results = results_df[results_df['model'] == model]\n",
        "    if len(model_results) > 0:\n",
        "        print(f\"\\n{model} Style Transfer:\")\n",
        "        print(f\"  Number of images: {len(model_results)}\")\n",
        "        print(f\"  Mean Van Gogh probability (Judge): {model_results['judge_van_gogh_prob'].mean():.4f}\")\n",
        "        print(f\"  Std Van Gogh probability (Judge): {model_results['judge_van_gogh_prob'].std():.4f}\")\n",
        "        print(f\"  Predicted as Van Gogh: {model_results['judge_prediction'].sum()}/{len(model_results)}\")\n",
        "        \n",
        "        if 'VGG19_classifier_van_gogh_prob' in model_results.columns:\n",
        "            vgg_probs = model_results['VGG19_classifier_van_gogh_prob'].dropna()\n",
        "            if len(vgg_probs) > 0:\n",
        "                print(f\"  Mean Van Gogh probability (VGG-19 Classifier): {vgg_probs.mean():.4f}\")\n",
        "        \n",
        "        if 'AlexNet_classifier_van_gogh_prob' in model_results.columns:\n",
        "            alexnet_probs = model_results['AlexNet_classifier_van_gogh_prob'].dropna()\n",
        "            if len(alexnet_probs) > 0:\n",
        "                print(f\"  Mean Van Gogh probability (AlexNet Classifier): {alexnet_probs.mean():.4f}\")\n",
        "\n",
        "# Comparison between VGG-19 and AlexNet\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VGG-19 vs ALEXNET COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "vgg19_mean = results_df[results_df['model'] == 'VGG19']['judge_van_gogh_prob'].mean()\n",
        "alexnet_mean = results_df[results_df['model'] == 'AlexNet']['judge_van_gogh_prob'].mean()\n",
        "\n",
        "print(f\"\\nVGG-19 mean Van Gogh probability: {vgg19_mean:.4f}\")\n",
        "print(f\"AlexNet mean Van Gogh probability: {alexnet_mean:.4f}\")\n",
        "print(f\"Difference: {abs(vgg19_mean - alexnet_mean):.4f}\")\n",
        "\n",
        "if vgg19_mean > alexnet_mean:\n",
        "    print(\"\\nVGG-19 produces more 'Van Gogh-like' results according to the classifier\")\n",
        "else:\n",
        "    print(\"\\nAlexNet produces more 'Van Gogh-like' results according to the classifier\")\n",
        "\n",
        "# Save results\n",
        "results_df.to_csv('/kaggle/working/style_transfer_results.csv', index=False)\n",
        "print(\"\\nResults saved to 'style_transfer_results.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some example results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXAMPLE STYLIZED IMAGES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Show top 6 results by Van Gogh probability\n",
        "top_results = sorted(all_results, key=lambda x: x['judge_van_gogh_prob'], reverse=True)[:6]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('Top 6 Stylized Images (by Van Gogh Probability)', fontsize=16, fontweight='bold')\n",
        "\n",
        "for idx, result in enumerate(top_results):\n",
        "    row = idx // 3\n",
        "    col = idx % 3\n",
        "    \n",
        "    # Display image\n",
        "    image = result['stylized_image'].cpu().clone().detach().squeeze(0)\n",
        "    inv_normalize = transforms.Normalize(\n",
        "        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "        std=[1/0.229, 1/0.224, 1/0.225]\n",
        "    )\n",
        "    image = inv_normalize(image)\n",
        "    image = transforms.ToPILImage()(image.clamp(0, 1))\n",
        "    \n",
        "    axes[row, col].imshow(image)\n",
        "    title = f\"{result['model_name']}\\nProb: {result['judge_van_gogh_prob']:.3f}\"\n",
        "    axes[row, col].set_title(title, fontsize=10)\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/kaggle/working/top_stylized_images.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Saved: top_stylized_images.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\"*60)\n",
        "print(\"PART B - FINAL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nPart 2B: Hyperparameter Search\")\n",
        "print(f\"  Optimal content_weight: {best_style_transfer_params.get('content_weight', 'N/A')}\")\n",
        "print(f\"  Optimal style_weight: {best_style_transfer_params.get('style_weight', 'N/A')}\")\n",
        "if 'study' in globals():\n",
        "    print(f\"  Best Van Gogh probability achieved: {study.best_value:.4f}\")\n",
        "\n",
        "print(\"\\nPart 2C: Application & Evaluation\")\n",
        "if 'all_results' in globals():\n",
        "    print(f\"  Total style transfers completed: {len(all_results)}\")\n",
        "if 'num_content' in globals():\n",
        "    print(f\"  Content images used: {num_content}\")\n",
        "if 'num_styles' in globals():\n",
        "    print(f\"  Style images used: {num_styles}\")\n",
        "if 'CONSISTENT_NUM_STEPS' in globals():\n",
        "    print(f\"  Optimization steps per image: {CONSISTENT_NUM_STEPS}\")\n",
        "\n",
        "print(\"\\nModel Comparison:\")\n",
        "if 'vgg19_mean' in globals() and 'alexnet_mean' in globals():\n",
        "    print(f\"  VGG-19 mean probability: {vgg19_mean:.4f}\")\n",
        "    print(f\"  AlexNet mean probability: {alexnet_mean:.4f}\")\n",
        "else:\n",
        "    print(\"  Run results analysis cell to see comparison\")\n",
        "\n",
        "print(\"\\nSaved Files:\")\n",
        "print(\"  - best_style_transfer_params.pkl\")\n",
        "print(\"  - style_transfer_results.csv\")\n",
        "print(\"  - top_stylized_images.png\")\n",
        "print(\"  - stylized_images/ (directory with all stylized images)\")\n",
        "\n",
        "print(\"\\nPart B Complete!\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
